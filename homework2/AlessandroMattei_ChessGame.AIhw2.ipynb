{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HOMEWORK 1 - Chess Game\n",
    "**Student:** Alessandro Mattei\n",
    "\n",
    "**Matricola:** 295411\n",
    "\n",
    "**Email:** alessandro.mattei1@student.univaq.it\n",
    "\n",
    "The main components used for the implementation will be presented:\n",
    "   - Class Agent\n",
    "   - Class Game (ChessGame)\n",
    "   - Class State (StateChessGame)\n",
    "   - Heuristics (HardBoardEvaluationChessGame and SoftBoardEvaluationChessGame)\n",
    "   - Observation (ObservationBoard) \n",
    "   - Search Algorithm (MinMaxAplaBetaPruning, MinMaxAlphaBetaPruningH0Cut, MinMaxAlphaBetaPruningHlCut, MinMaxAlphaBetaPruningRegressorCut)\n",
    "   - Nonlinear Regressor\n",
    "   - CSV generator for the nonlinear regressor\n",
    "\n",
    "# Agent Class\n",
    "Represents an agent that can act based on a given search algorithm and its current view of the world."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38339eafa8cc80b5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    Represents an agent that can act based on a given search algorithm and its current view of the world.\n",
    "\n",
    "    Attributes:\n",
    "        search_algorithm: A search algorithm that the agent uses to make decisions.\n",
    "        view: The agent's current view of the world.\n",
    "        old_view: The agent's previous view of the world.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, search_algorithm, initial_state):\n",
    "        \"\"\"\n",
    "        Initializes the Agent with a search algorithm and an initial state.\n",
    "\n",
    "        :param search_algorithm: The search algorithm to be used by the agent.\n",
    "        :param initial_state: The initial state of the world as perceived by the agent.\n",
    "        \"\"\"\n",
    "        self.search_algorithm = search_algorithm\n",
    "        self.view = initial_state\n",
    "        self.old_view = None\n",
    "\n",
    "    def do_action(self, current_state_world):\n",
    "        \"\"\"\n",
    "        Updates the agent's view based on the current state of the world and the search algorithm.\n",
    "        :param current_state_world: The current state of the world.\n",
    "        :return: The updated view of the agent.\n",
    "        \"\"\"\n",
    "        self.view = self.search_algorithm.search(current_state_world)\n",
    "        self.old_view = current_state_world\n",
    "        return self.view\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.257862600Z",
     "start_time": "2023-10-29T17:06:19.205111200Z"
    }
   },
   "id": "f14441fc8c82aba7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# State\n",
    "Represents a state in a chess game, including the board configuration and various heuristic evaluations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "440b47e4f7ea4c93"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "\n",
    "class StateChessGame:\n",
    "    \"\"\"\n",
    "    Represents a state in a chess game, including the board configuration and various heuristic evaluations.\n",
    "\n",
    "    Attributes:\n",
    "        game_board (chess.Board): The current chess board configuration.\n",
    "        parent_state (StateChessGame): The parent state from which this state is derived.\n",
    "        move (chess.Move): The move that led to this state.\n",
    "        h (float): General heuristic value for the state.\n",
    "        h0 (float): Heuristic value used for h0 cutoff.\n",
    "        hl (float): Heuristic value used for hl cutoff.\n",
    "        hr (float): Heuristic value used for nonlinear regressor cutoff.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game_board=None, state_parent=None, move=None):\n",
    "        \"\"\"\n",
    "        Initializes a new game state.\n",
    "\n",
    "        :param game_board: The current chess board configuration. If None, initializes a new chess board.\n",
    "        :param state_parent: The parent state from which this state is derived.\n",
    "        :param move: The move that led to this state.\n",
    "        \"\"\"\n",
    "        self.game_board = game_board  # The current chess board (chess.Board object).\n",
    "        self.parent_state = state_parent  # The parent state from which this state is derived.\n",
    "        self.move = move  # The move that led to this state.\n",
    "        self.h = None  # General heuristic value for the state.\n",
    "        self.h0 = None  # Heuristic value used for h0 cutoff.\n",
    "        self.hl = None  # Heuristic value used for hl cutoff.\n",
    "        self.hr = None  # Heuristic value used for nonlinear regressor cutoff.\n",
    "\n",
    "        # If no game board is provided, initialize a new chess board.\n",
    "        if self.game_board is None:\n",
    "            self.game_board = chess.Board()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Checks if this state is equal to another state. States are considered equal if they have the same game\n",
    "        board configuration.\n",
    "\n",
    "        :param other: The other StateChessGame object to compare with.\n",
    "        :return: True if the states are equal, False otherwise.\n",
    "        \"\"\"\n",
    "        if not isinstance(other, StateChessGame):\n",
    "            return False\n",
    "        return self.game_board == other.game_board\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        \"\"\"\n",
    "        Checks if this state is not equal to another state. It relies on the __eq__ method.\n",
    "\n",
    "        :param other: The other StateChessGame object to compare with.\n",
    "        :return: True if the states are not equal, False otherwise.\n",
    "        \"\"\"\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Generates a hash for the state. This is based on the string representation of the game board, allowing the state\n",
    "        to be used in hash tables or sets.\n",
    "\n",
    "        :return: The hash of the state.\n",
    "        \"\"\"\n",
    "        return hash(str(self.game_board))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.334635Z",
     "start_time": "2023-10-29T17:06:19.224330500Z"
    }
   },
   "id": "a37c211095dda285"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Game Class\n",
    "Represents a chess game, providing functionalities to manage the game state and compute possible moves."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfb969b30be40656"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "from chessgame.StateChessGame import StateChessGame\n",
    "\n",
    "\n",
    "class ChessGame:\n",
    "    \"\"\"\n",
    "    Represents a chess game, providing functionalities to manage the game state and compute possible moves.\n",
    "\n",
    "    Attributes:\n",
    "        game_board (chess.Board): The current chess board configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game_board=None):\n",
    "        \"\"\"\n",
    "        Initializes a new chess game.\n",
    "\n",
    "        :param game_board: The current chess board configuration. If None, initializes a new chess board.\n",
    "        \"\"\"\n",
    "        self.game_board = game_board  # The current chess board.\n",
    "\n",
    "        # If no game board is provided, initialize a new chess board.\n",
    "        if game_board is None:\n",
    "            self.game_board = chess.Board()\n",
    "\n",
    "    def neighbors(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Generates all possible next states (neighbors) from a given state.\n",
    "\n",
    "        :param state: The current state of the chess game from which to compute neighbors.\n",
    "        :return: A list of StateChessGame objects representing possible next states.\n",
    "        \"\"\"\n",
    "        neighbors = []\n",
    "\n",
    "        # Iterate through all legal moves from the current state.\n",
    "        for legal_move in state.game_board.legal_moves:\n",
    "            # Copy the current game board and make the legal move.\n",
    "            new_game_board = state.game_board.copy()\n",
    "            new_game_board.push(legal_move)\n",
    "\n",
    "            # Create a new StateChessGame object for the resulting game state.\n",
    "            neighbor = StateChessGame(game_board=new_game_board, state_parent=state, move=legal_move)\n",
    "            neighbors.append(neighbor)\n",
    "        return neighbors\n",
    "\n",
    "    def get_name_winner_player(self, game_board):\n",
    "        \"\"\"\n",
    "        Determines the name of the winning player if the game is in checkmate.\n",
    "\n",
    "        :param game_board: The chess board to check for checkmate and winner.\n",
    "        :return: The name of the winning player (\"White\" or \"Black\") if there's a checkmate, otherwise None.\n",
    "        \"\"\"\n",
    "        # Check if the current game state is a checkmate.\n",
    "        if game_board.is_checkmate():\n",
    "            # Get the outcome of the game.\n",
    "            outcome = game_board.outcome()\n",
    "            if outcome is not None:\n",
    "                # Return \"White\" or \"Black\" depending on the winner.\n",
    "                return \"White\" if outcome.winner else \"Black\"\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.334635Z",
     "start_time": "2023-10-29T17:06:19.326060400Z"
    }
   },
   "id": "64e3290e0dcd39b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Heuristics\n",
    "## Single Evaluations\n",
    "### Constants"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bac4e63a1657e95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "PIECE_VALUE = {\n",
    "    chess.PAWN: 1,\n",
    "    chess.KNIGHT: 3,\n",
    "    chess.BISHOP: 3,\n",
    "    chess.ROOK: 5,\n",
    "    chess.QUEEN: 9,\n",
    "    chess.KING: 0  # Il valore del re Ã¨ gestito separatamente\n",
    "}\n",
    "\n",
    "# Tabelle di posizione per il pedone\n",
    "PAWN_TABLE = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    5, 10, 10, -20, -20, 10, 10, 5,\n",
    "    5, -5, -10, 0, 0, -10, -5, 5,\n",
    "    0, 0, 0, 20, 20, 0, 0, 0,\n",
    "    5, 5, 10, 25, 25, 10, 5, 5,\n",
    "    10, 10, 20, 30, 30, 20, 10, 10,\n",
    "    50, 50, 50, 50, 50, 50, 50, 50,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per il cavallo\n",
    "KNIGHT_TABLE = [\n",
    "    -50, -40, -30, -30, -30, -30, -40, -50,\n",
    "    -40, -20, 0, 5, 5, 0, -20, -40,\n",
    "    -30, 5, 10, 15, 15, 10, 5, -30,\n",
    "    -30, 0, 15, 20, 20, 15, 0, -30,\n",
    "    -30, 5, 15, 20, 20, 15, 5, -30,\n",
    "    -30, 0, 10, 15, 15, 10, 0, -30,\n",
    "    -40, -20, 0, 0, 0, 0, -20, -40,\n",
    "    -50, -40, -30, -30, -30, -30, -40, -50,\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per l'alfiere\n",
    "BISHOP_TABLE = [\n",
    "    -20, -10, -10, -10, -10, -10, -10, -20,\n",
    "    -10, 5, 0, 0, 0, 0, 5, -10,\n",
    "    -10, 10, 10, 10, 10, 10, 10, -10,\n",
    "    -10, 0, 10, 10, 10, 10, 0, -10,\n",
    "    -10, 5, 5, 10, 10, 5, 5, -10,\n",
    "    -10, 0, 5, 10, 10, 5, 0, -10,\n",
    "    -10, 0, 0, 0, 0, 0, 0, -10,\n",
    "    -20, -10, -10, -10, -10, -10, -10, -20\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per la torre\n",
    "ROOK_TABLE = [\n",
    "    0, 0, 0, 5, 5, 0, 0, 0,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    5, 10, 10, 10, 10, 10, 10, 5,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per la regina\n",
    "QUEEEN_TABLE = [\n",
    "    -20, -10, -10, -5, -5, -10, -10, -20,\n",
    "    -10, 0, 5, 0, 0, 0, 0, -10,\n",
    "    -10, 5, 5, 5, 5, 5, 0, -10,\n",
    "    0, 0, 5, 5, 5, 5, 0, -5,\n",
    "    -5, 0, 5, 5, 5, 5, 0, -5,\n",
    "    -10, 0, 5, 5, 5, 5, 0, -10,\n",
    "    -10, 0, 0, 0, 0, 0, 0, -10,\n",
    "    -20, -10, -10, -5, -5, -10, -10, -20\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per il re (inizio gioco)\n",
    "KING_INITGAME_TABLE = [\n",
    "    20, 30, 10, 0, 0, 10, 30, 20,\n",
    "    20, 20, 0, 0, 0, 0, 20, 20,\n",
    "    -10, -20, -20, -20, -20, -20, -20, -10,\n",
    "    -20, -30, -30, -40, -40, -30, -30, -20,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per il re (fine gioco)\n",
    "KING_ENDGAME_TABLE = [\n",
    "    -50, -40, -30, -20, -20, -30, -40, -50,\n",
    "    -30, -20, -10, 0, 0, -10, -20, -30,\n",
    "    -30, -10, 20, 30, 30, 20, -10, -30,\n",
    "    -30, -10, 30, 40, 40, 30, -10, -30,\n",
    "    -30, -10, 30, 40, 40, 30, -10, -30,\n",
    "    -30, -10, 20, 30, 30, 20, -10, -30,\n",
    "    -30, -30, 0, 0, 0, 0, -30, -30,\n",
    "    -50, -30, -30, -30, -30, -30, -30, -50\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55eaa0e7baa6d5b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate Board Without King\n",
    "\n",
    "Provides heuristic evaluation of a chess board state, focusing on piece values and game conditions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6eb53a65cfd2a44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluateBoardWithoutKing:\n",
    "    \"\"\"\n",
    "    Provides heuristic evaluation of a chess board state, focusing on piece values and game conditions.\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): Flag to indicate whether to evaluate endgame phases differently.\n",
    "        normalize_result (bool): Flag to indicate whether to normalize the evaluation result.\n",
    "        h_max_value (int): Maximum heuristic value for normalization.\n",
    "        h_min_value (int): Minimum heuristic value for normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation and result normalization.\n",
    "\n",
    "        :param evaluate_end_game_phase: Set to True to evaluate endgame phases differently.\n",
    "        :param normalize_result: Set to True to normalize the evaluation result.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase  # Flag to evaluate endgame phases.\n",
    "        self.normalize_result = normalize_result  # Flag to normalize the evaluation result.\n",
    "        self.h_max_value = 99  # Maximum heuristic value for normalization.\n",
    "        self.h_min_value = -99  # Minimum heuristic value for normalization.\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the heuristic of a given game state.\n",
    "\n",
    "        :param state: StateChessGame object representing the current state of the chess game.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        # Evaluates endgame phase or normalizes the result based on the flags set in the constructor.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        Similar to h() but operates directly on a chess board and allows specifying normalization bounds.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Evaluates the endgame phase, normalizes the result, or provides raw evaluation.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Private method for raw heuristic evaluation of a board.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The raw heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "\n",
    "        # If the game is over, returns high positive or negative values for checkmate, and zero for other endings.\n",
    "        if board.is_game_over():\n",
    "            if board.is_checkmate():\n",
    "                return -99 if board.turn else 99\n",
    "            else:\n",
    "                return 0  # Handles stalemate and insufficient material.\n",
    "\n",
    "        # Piece-based evaluation, optimized.\n",
    "        eval = sum(PIECE_VALUE[piece] * (len(board.pieces(piece, chess.WHITE)) - len(board.pieces(piece, chess.BLACK)))\n",
    "                   for piece in PIECE_VALUE)\n",
    "        # Slightly favors the player whose turn it is, as they might have the initiative.\n",
    "        eval += 0.1 if board.turn else -0.1\n",
    "\n",
    "        return eval\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb9bf11e1fcfcec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Central Control Score\n",
    "\n",
    "Provides heuristic evaluation of a chess board state with a focus on the control of central squares."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d9340a75c59409c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluateCentralControlScore:\n",
    "    \"\"\"\n",
    "    Provides heuristic evaluation of a chess board state with a focus on the control of central squares.\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): Flag to indicate whether to evaluate endgame phases differently.\n",
    "        normalize_result (bool): Flag to indicate whether to normalize the evaluation result.\n",
    "        h_max_value (float): Maximum heuristic value for normalization.\n",
    "        h_min_value (float): Minimum heuristic value for normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation and result normalization.\n",
    "\n",
    "        :param evaluate_end_game_phase: Set to True to evaluate endgame phases differently.\n",
    "        :param normalize_result: Set to True to normalize the evaluation result.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase  # Flag to evaluate endgame phases.\n",
    "        self.normalize_result = normalize_result  # Flag to normalize the evaluation result.\n",
    "        self.h_max_value = 1.2  # Maximum heuristic value for normalization.\n",
    "        self.h_min_value = -1.2  # Minimum heuristic value for normalization.\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the heuristic of a given game state.\n",
    "\n",
    "        :param state: StateChessGame object representing the current state of the chess game.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        # Evaluates endgame phase or normalizes the result based on the constructor's flags.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        Similar to h() but operates directly on a chess board and allows specifying normalization bounds.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Evaluates the endgame phase, normalizes the result, or provides raw evaluation.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Private method for raw heuristic evaluation of a board.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The raw heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "\n",
    "        # Assign points for control of each central square.\n",
    "        center_squares = [chess.D4, chess.E4, chess.D5, chess.E5]\n",
    "        score = 0\n",
    "        central_square_control = 0.3  # Value to calibrate based on your specific heuristic.\n",
    "\n",
    "        # Check if central squares are controlled by White or Black.\n",
    "        for square in center_squares:\n",
    "            if board.is_attacked_by(chess.WHITE, square):\n",
    "                score += central_square_control\n",
    "            if board.is_attacked_by(chess.BLACK, square):\n",
    "                score -= central_square_control\n",
    "\n",
    "        # Adjust the score for the current player.\n",
    "        return score if board.turn == chess.WHITE else -score\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e1f0f1247ff5eed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate King Safety\n",
    "\n",
    "A class to evaluate the safety of the king in a chess game. It assesses the level of threat or safety for both kings based on the game board configuration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "541b865006da4f6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluateKingSafety:\n",
    "    \"\"\"\n",
    "    A class to evaluate the safety of the king in a chess game. It assesses the level of threat or safety\n",
    "    for both kings based on the game board configuration.\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): Flag to indicate if endgame phases should be evaluated differently.\n",
    "        normalize_result (bool): Flag to determine if the evaluation result should be normalized.\n",
    "        h_max_value (float): Maximum heuristic value for normalization purposes.\n",
    "        h_min_value (float): Minimum heuristic value for normalization purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation and result normalization.\n",
    "\n",
    "        :param evaluate_end_game_phase: Set to True to apply special evaluations in endgame phases.\n",
    "        :param normalize_result: Set to True to normalize the evaluation score within a specific range.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase\n",
    "        self.normalize_result = normalize_result\n",
    "        self.h_max_value = 9.5  # Max heuristic value for normalization.\n",
    "        self.h_min_value = -9.5  # Min heuristic value for normalization\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the safety of the king based on the current game state.\n",
    "\n",
    "        :param state: StateChessGame object representing the current state of the chess game.\n",
    "        :return: The heuristic value representing the king's safety.\n",
    "        \"\"\"\n",
    "        # Applies special endgame evaluation or normalization as per the initialization flags.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        A variant of the h() method, working directly on a chess board.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The heuristic value representing the king's safety.\n",
    "        \"\"\"\n",
    "        # Handles endgame phase evaluation or normalization as specified.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Private method for raw heuristic evaluation of the king's safety on the board.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The raw heuristic value representing the king's safety.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "        score = 0\n",
    "        pawn_cover_score = 0.5\n",
    "        attacked_square_score = -0.75\n",
    "\n",
    "        # Bit masks for black and white pedestrians\n",
    "        white_pawns = board.pieces(chess.PAWN, chess.WHITE)\n",
    "        black_pawns = board.pieces(chess.PAWN, chess.BLACK)\n",
    "\n",
    "        # Calculation for the white king\n",
    "        white_king_square = board.king(chess.WHITE)\n",
    "        white_king_attacks = board.attacks(white_king_square)\n",
    "        white_king_zone = white_pawns & white_king_attacks\n",
    "        score += pawn_cover_score * bin(white_king_zone).count('1')\n",
    "\n",
    "        # Controlla le caselle attaccate dai neri nella zona del re bianco\n",
    "        for square in white_king_attacks:\n",
    "            if board.is_attacked_by(chess.BLACK, square):\n",
    "                score += attacked_square_score\n",
    "\n",
    "        # Check the squares attacked by blacks in the white king's area\n",
    "        black_king_square = board.king(chess.BLACK)\n",
    "        black_king_attacks = board.attacks(black_king_square)\n",
    "        black_king_zone = black_pawns & black_king_attacks\n",
    "        score -= pawn_cover_score * bin(black_king_zone).count('1')\n",
    "\n",
    "        # Check the squares attacked by whites in the black king's area\n",
    "        for square in black_king_attacks:\n",
    "            if board.is_attacked_by(chess.WHITE, square):\n",
    "                score -= attacked_square_score\n",
    "\n",
    "        return score\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "646330cb7b8bd52c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Mobility\n",
    "\n",
    "This class evaluates the mobility of pieces in a chess game. It calculates a score based on the number of legal moves available for white and black, representing the degree of freedom and potential for offensive or defensive actions in the game."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab4fc7ddc72594cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluateMobility:\n",
    "    \"\"\"\n",
    "    This class evaluates the mobility of pieces in a chess game. It calculates a score based on\n",
    "    the number of legal moves available for white and black, representing the degree of freedom\n",
    "    and potential for offensive or defensive actions in the game.\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): Indicates if the endgame should be evaluated differently.\n",
    "        normalize_result (bool): Determines if the evaluation score should be normalized.\n",
    "        h_max_value (float): The upper limit for normalization of the heuristic score.\n",
    "        h_min_value (float): The lower limit for normalization of the heuristic score.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation and result normalization.\n",
    "\n",
    "        :param evaluate_end_game_phase: Set to True for specialized evaluations in endgame phases.\n",
    "        :param normalize_result: Set to True to normalize the evaluation score within a range.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase\n",
    "        self.normalize_result = normalize_result\n",
    "        self.h_max_value = 90  # Max heuristic value for normalization.\n",
    "        self.h_min_value = -10  # Min heuristic value for normalization.\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the mobility based on the current game state. Determines if special handling\n",
    "        for the endgame or normalization of results is required.\n",
    "\n",
    "        :param state: StateChessGame object representing the current state of the chess game.\n",
    "        :return: A heuristic value representing the mobility balance.\n",
    "        \"\"\"\n",
    "        # Applies endgame evaluation or normalization based on the initialization flags.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        A similar function to h(), but operates directly on a chess board and allows for custom\n",
    "        normalization bounds.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: A heuristic value representing the mobility balance.\n",
    "        \"\"\"\n",
    "        # Handles endgame evaluation or normalization based on the board state.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Private method for the raw heuristic evaluation of mobility on the board. It calculates\n",
    "        the difference in the number of legal moves available to each player.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The raw heuristic value representing the mobility balance.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "        white_mobility = 0\n",
    "        black_mobility = 0\n",
    "\n",
    "        # Calculate the mobility for both white and black pieces.\n",
    "        for move in board.legal_moves:\n",
    "            if board.color_at(move.from_square) == chess.WHITE:\n",
    "                white_mobility += 1\n",
    "            else:\n",
    "                black_mobility += 1\n",
    "\n",
    "        mobility_balance = white_mobility - black_mobility\n",
    "        # Return the mobility balance, adjusted for the current player's turn.\n",
    "        return mobility_balance if board.turn == chess.WHITE else -mobility_balance\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccea65c293e29c43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Pawn Structure\n",
    "\n",
    "This class evaluates the pawn structure in a chess game. It analyzes various factors like isolated, doubled, backward, and passed pawns, computing a score to represent the strategic and positional strength of the pawn structure."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0a6fab223074995"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluatePawnStructure:\n",
    "    \"\"\"\n",
    "    This class evaluates the pawn structure in a chess game. It analyzes various factors like isolated,\n",
    "    doubled, backward, and passed pawns, computing a score to represent the strategic and positional strength\n",
    "    of the pawn structure.\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): Indicates if the endgame should be evaluated differently.\n",
    "        file_bb (list): Bitboards representing each file on the chessboard.\n",
    "        rank_bb (list): Bitboards representing each rank on the chessboard.\n",
    "        advance_shifts (dict): Dict for calculating the square index after advancing a pawn.\n",
    "        normalize_result (bool): Determines if the evaluation score should be normalized.\n",
    "        h_max_value (float): The upper limit for normalization of the heuristic score.\n",
    "        h_min_value (float): The lower limit for normalization of the heuristic score.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation, pawn advancement, and result normalization.\n",
    "\n",
    "        :param evaluate_end_game_phase: Set to True for specialized evaluations in endgame phases.\n",
    "        :param normalize_result: Set to True to normalize the evaluation score within a range.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase  # Flag to adjust evaluation in endgame phases.\n",
    "        self.file_bb = [chess.BB_FILES[f] for f in range(8)]  # Bitboards for each file (column) of the chessboard.\n",
    "        self.rank_bb = [chess.BB_RANKS[r] for r in range(8)]  # Bitboards for each rank (row) of the chessboard.\n",
    "        self.advance_shifts = {chess.WHITE: 8, chess.BLACK: -8}  # Square shift for pawn advancement based on color.\n",
    "        self.normalize_result = normalize_result  # Flag to normalize the evaluation score.\n",
    "        self.h_max_value = 430  # Max heuristic value for normalization.\n",
    "        self.h_min_value = -430  # Min heuristic value for normalization.\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the pawn structure based on the current game state. Determines if special handling\n",
    "        for the endgame or normalization of results is required.\n",
    "\n",
    "        :param state: StateChessGame object representing the current state of the chess game.\n",
    "        :return: A heuristic value representing the pawn structure.\n",
    "        \"\"\"\n",
    "        # Applies endgame evaluation or normalization based on the initialization flags.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        A similar function to h(), but operates directly on a chess board and allows for custom\n",
    "        normalization bounds.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: A heuristic value representing the pawn structure.\n",
    "        \"\"\"\n",
    "        # Handles endgame evaluation or normalization based on the board state.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __pawn_structure_score(self, pawns, color, board):\n",
    "        score = 0\n",
    "        our_pawns_bb = int(pawns)  # Convert to integer bitboard if it's not already\n",
    "        all_pawns_bb = int(board.pieces(chess.PAWN, chess.WHITE)) | int(board.pieces(chess.PAWN, chess.BLACK))\n",
    "\n",
    "        # Precompute pawn presence for files using bitwise operations\n",
    "        pawns_on_file = [bool(our_pawns_bb & self.file_bb[f]) for f in range(8)]\n",
    "\n",
    "        for square in chess.SquareSet(our_pawns_bb):\n",
    "            file = chess.square_file(square)\n",
    "            rank = chess.square_rank(square)\n",
    "\n",
    "            # Isolated pawns\n",
    "            if not (pawns_on_file[file - 1] if file > 0 else False) and \\\n",
    "                    not (pawns_on_file[file + 1] if file < 7 else False):\n",
    "                score -= 20\n",
    "\n",
    "            # Doubled pawns\n",
    "            if bin(our_pawns_bb & self.file_bb[file]).count('1') > 1:\n",
    "                score -= 10\n",
    "\n",
    "            # Backward pawns\n",
    "            supported = False\n",
    "            advance_square = square + self.advance_shifts[color]\n",
    "            support_squares = [square - 1, square + 1] + \\\n",
    "                              [advance_square - 1, advance_square + 1]\n",
    "\n",
    "            # Check if the pawn is supported by our other pawns\n",
    "            for support_sq in support_squares:\n",
    "                if 0 <= support_sq < 64 and (all_pawns_bb & (1 << support_sq)):\n",
    "                    supported = True\n",
    "                    break\n",
    "            if not supported and 0 <= advance_square < 64 and board.piece_at(advance_square) is None:\n",
    "                score -= 15\n",
    "\n",
    "        return score\n",
    "\n",
    "    def __passed_pawn_score(self, our_pawns, their_pawns, color):\n",
    "        \"\"\"\n",
    "        Calculates a score based on the structure of the pawns for a given color. It considers factors such\n",
    "        as isolated, doubled, and backward pawns.\n",
    "\n",
    "        :param color: The color of the pawns to be evaluated (chess.WHITE or chess.BLACK).\n",
    "        :return: An integer score representing the structural strengths and weaknesses of the pawns.\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        their_pawns_bb = int(their_pawns)  # Assicurati che sia un bitboard intero\n",
    "        for our_pawn in our_pawns:\n",
    "            file = chess.square_file(our_pawn)\n",
    "            rank = chess.square_rank(our_pawn)\n",
    "            passed = True\n",
    "            if color == chess.WHITE:\n",
    "                for r in range(rank + 1, 8):\n",
    "                    if self.file_bb[file] & self.rank_bb[r] & their_pawns_bb:  # Utilizzo bitboard intero\n",
    "                        passed = False\n",
    "                        break\n",
    "            else:\n",
    "                for r in range(rank - 1, -1, -1):\n",
    "                    if self.file_bb[file] & self.rank_bb[r] & their_pawns_bb:  # Utilizzo bitboard intero\n",
    "                        passed = False\n",
    "                        break\n",
    "            if passed:\n",
    "                score += 50\n",
    "\n",
    "        return score\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Private method for the raw heuristic evaluation of the pawn structure on the board. It considers\n",
    "        the overall structure, including both white and black pawns, and computes a combined score.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The raw heuristic value representing the overall pawn structure.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "        score = 0\n",
    "        # Get the positions of white and black pawns.\n",
    "        white_pawns = board.pieces(chess.PAWN, chess.WHITE)\n",
    "        black_pawns = board.pieces(chess.PAWN, chess.BLACK)\n",
    "\n",
    "        # Get the positions of white and black pawns.\n",
    "        score += self.__pawn_structure_score(white_pawns, chess.WHITE, board)\n",
    "        score -= self.__pawn_structure_score(black_pawns, chess.BLACK, board)\n",
    "\n",
    "        # Evaluate passed pawn score for both sides.\n",
    "        score += self.__passed_pawn_score(white_pawns, black_pawns, chess.WHITE)\n",
    "        score -= self.__passed_pawn_score(black_pawns, white_pawns, chess.BLACK)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eb75de419213939"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Piece Positions\n",
    "\n",
    "This class evaluates the positions of pieces on a chessboard. It calculates a score based on the positioning of each piece type according to specific positional tables, especially considering different game phases (e.g., opening, endgame)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8daa512420f068c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluatePiecePositions:\n",
    "    \"\"\"\n",
    "    This class evaluates the positions of pieces on a chessboard. It calculates a score based on the\n",
    "    positioning of each piece type according to specific positional tables, especially considering different\n",
    "    game phases (e.g., opening, endgame).\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): If true, the evaluation changes for the endgame phase.\n",
    "        normalize_result (bool): If true, normalizes the evaluation score within a specific range.\n",
    "        h_max_value (float): Maximum value for normalization.\n",
    "        h_min_value (float): Minimum value for normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation and normalization of results.\n",
    "\n",
    "        :param evaluate_end_game_phase: Indicates whether to apply a different evaluation strategy for endgame.\n",
    "        :param normalize_result: Indicates whether to normalize the evaluation score.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase  # Determines if endgame is evaluated differently.\n",
    "        self.normalize_result = normalize_result  # Determines if score should be normalized.\n",
    "        self.h_max_value = 505  # Maximum value for heuristic normalization.\n",
    "        self.h_min_value = -420  # Minimum value for heuristic normalization.\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the piece positions for the given state of the chess game.\n",
    "\n",
    "        :param state: The current state of the chess game.\n",
    "        :return: A heuristic value representing the evaluation of piece positions.\n",
    "        \"\"\"\n",
    "        # Applies endgame evaluation or normalization based on the initialization flags.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        A variant of the h() method, working directly on a chess board. It allows for custom normalization bounds.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: A heuristic value representing the piece positions.\n",
    "        \"\"\"\n",
    "        # Handles endgame evaluation or normalization based on the board state.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __evaluate_piece_positions(self, board, piece_table, piece_type, color):\n",
    "        \"\"\"\n",
    "        Evaluates the positions of a specific type of piece on the board based on a predefined table.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :param piece_table: A table with positional values for each square of the board.\n",
    "        :param piece_type: Type of the piece to evaluate.\n",
    "        :param color: Color of the pieces to evaluate.\n",
    "        :return: A score based on the positioning of the pieces.\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        pieces = board.pieces(piece_type, color)\n",
    "        # Calculate the score for each piece based on its position.\n",
    "        for square in pieces:\n",
    "            piece_position_value = piece_table[square]\n",
    "            # Adjust score based on the piece color.\n",
    "            score += piece_position_value if color == chess.WHITE else -piece_position_value\n",
    "        return score\n",
    "\n",
    "    def __is_endgame(self, board):\n",
    "        \"\"\"\n",
    "        Determines if the current board state is in the endgame phase.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: True if it's the endgame phase, False otherwise.\n",
    "        \"\"\"\n",
    "        # Regine\n",
    "        white_queens = len(board.pieces(chess.QUEEN, chess.WHITE))\n",
    "        black_queens = len(board.pieces(chess.QUEEN, chess.BLACK))\n",
    "\n",
    "        # se entrambi i lati non hanno Regine -> endgame phase\n",
    "        if white_queens == 0 and black_queens == 0:\n",
    "            return True\n",
    "\n",
    "        # Minorpieces\n",
    "        white_bishops = len(board.pieces(chess.BISHOP, chess.WHITE))\n",
    "        black_bishops = len(board.pieces(chess.BISHOP, chess.BLACK))\n",
    "        white_knights = len(board.pieces(chess.KNIGHT, chess.WHITE))\n",
    "        black_knights = len(board.pieces(chess.KNIGHT, chess.BLACK))\n",
    "        white_minors = white_bishops + white_knights\n",
    "        black_minors = black_bishops + black_knights\n",
    "\n",
    "        white_rooks = len(board.pieces(chess.ROOK, chess.WHITE))\n",
    "        black_rooks = len(board.pieces(chess.ROOK, chess.BLACK))\n",
    "\n",
    "        # se ogni lato che ha una regina, non ha altri pezzi oppure ha\n",
    "        # 1 Minorpiece al massimo -> endgame phase\n",
    "        white_endgame_condition_with_queen = (\n",
    "                white_queens == 1 and (white_rooks == 0 and white_minors <= 1)\n",
    "        )\n",
    "        black_endgame_condition_with_queen = (\n",
    "                black_queens == 1 and (black_rooks == 0 and black_minors <= 1)\n",
    "        )\n",
    "\n",
    "        if (\n",
    "                (white_endgame_condition_with_queen and black_queens == 0)\n",
    "                or (black_endgame_condition_with_queen and white_queens == 0)\n",
    "                or (\n",
    "                white_endgame_condition_with_queen\n",
    "                and black_endgame_condition_with_queen\n",
    "        )\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Calculates the total score based on the position of pieces on the board.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: A score representing the overall evaluation of piece positions.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "        total_score = 0\n",
    "        if self.__is_endgame(board):\n",
    "            king_table_to_use = KING_ENDGAME_TABLE\n",
    "        else:\n",
    "            king_table_to_use = KING_INITGAME_TABLE\n",
    "        total_score += self.__evaluate_piece_positions(board, PAWN_TABLE, chess.PAWN, chess.WHITE)\n",
    "        total_score += self.__evaluate_piece_positions(board, KNIGHT_TABLE, chess.KNIGHT, chess.WHITE)\n",
    "        total_score += self.__evaluate_piece_positions(board, BISHOP_TABLE, chess.BISHOP, chess.WHITE)\n",
    "        total_score += self.__evaluate_piece_positions(board, ROOK_TABLE, chess.ROOK, chess.WHITE)\n",
    "        total_score += self.__evaluate_piece_positions(board, QUEEEN_TABLE, chess.QUEEN, chess.WHITE)\n",
    "        total_score += self.__evaluate_piece_positions(board, king_table_to_use, chess.KING, chess.WHITE)\n",
    "\n",
    "        total_score -= self.__evaluate_piece_positions(board, PAWN_TABLE, chess.PAWN, chess.BLACK)\n",
    "        total_score -= self.__evaluate_piece_positions(board, KNIGHT_TABLE, chess.KNIGHT, chess.BLACK)\n",
    "        total_score -= self.__evaluate_piece_positions(board, BISHOP_TABLE, chess.BISHOP, chess.BLACK)\n",
    "        total_score -= self.__evaluate_piece_positions(board, ROOK_TABLE, chess.ROOK, chess.BLACK)\n",
    "        total_score -= self.__evaluate_piece_positions(board, QUEEEN_TABLE, chess.QUEEN, chess.BLACK)\n",
    "        total_score -= self.__evaluate_piece_positions(board, king_table_to_use, chess.KING, chess.BLACK)\n",
    "\n",
    "        return total_score\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "637c08bcfc63182c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HardBoardEvaluationChessGame\n",
    "\n",
    "This class provides an in-depth evaluation of a chess game board by integrating various evaluation metrics like material balance, central control, king safety, mobility, pawn structure, and piece positioning. It offers a holistic approach to assessing the strengths and weaknesses of a chess position, making it suitable for advanced analysis.\n",
    "\n",
    "Combined heuristics:\n",
    "   - evaluate_board_without_king: Evaluation component focusing on the board without considering the king's position.\n",
    "   - evaluate_central_control_score: Evaluation component focusing on the control of central squares.\n",
    "   - evaluate_king_safety: Evaluation component focusing on the safety of the king.\n",
    "   - evaluate_mobility: Evaluation component focusing on the mobility of pieces.\n",
    "   - evaluate_pawn_structure: Evaluation component focusing on the pawn structure.\n",
    "   - evaluate_piece_positions: Evaluation component focusing on the positions of all pieces except the king."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10760947ca340d92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class HardBoardEvaluationChessGame:\n",
    "    \"\"\"\n",
    "    This class provides an in-depth evaluation of a chess game board by integrating various evaluation\n",
    "    metrics like material balance, central control, king safety, mobility, pawn structure, and piece\n",
    "    positioning. It offers a holistic approach to assessing the strengths and weaknesses of a chess\n",
    "    position, making it suitable for advanced analysis.\n",
    "\n",
    "    Attributes:\n",
    "        balance_evaluation (bool): If True, combines evaluation scores using a weighted approach.\n",
    "                                   This gives a balanced evaluation considering all aspects of the game.\n",
    "        print_evaluation (bool): If True, prints the evaluation results for debugging or analysis purposes.\n",
    "        evaluate_board_without_king (EvaluateBoardWithoutKing): Evaluation component focusing on the board\n",
    "                                                                without considering the king's position.\n",
    "        evaluate_central_control_score (EvaluateCentralControlScore): Evaluation component focusing on\n",
    "                                                                      the control of central squares.\n",
    "        evaluate_king_safety (EvaluateKingSafety): Evaluation component focusing on the safety of the king.\n",
    "        evaluate_mobility (EvaluateMobility): Evaluation component focusing on the mobility of pieces.\n",
    "        evaluate_pawn_structure (EvaluatePawnStructure): Evaluation component focusing on the pawn structure.\n",
    "        evaluate_piece_positions (EvaluatePiecePositions): Evaluation component focusing on the positions\n",
    "                                                           of all pieces except the king.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, balance_evaluation=True, print_evaluation=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluation components for different aspects of the chess game.\n",
    "\n",
    "        :param balance_evaluation: If True, uses a weighted approach for combining different evaluation metrics.\n",
    "        :param print_evaluation: If True, prints the evaluation scores.\n",
    "        \"\"\"\n",
    "        self.balance_evaluation = balance_evaluation  # Flag to use weighted evaluation scores.\n",
    "        self.print_evaluation = print_evaluation  # Flag to print the evaluation results.\n",
    "        # Initialize individual evaluation components with normalization enabled.\n",
    "        self.evaluate_board_without_king = EvaluateBoardWithoutKing(normalize_result=True)\n",
    "        self.evaluate_central_control_score = EvaluateCentralControlScore(normalize_result=True)\n",
    "        self.evaluate_king_safety = EvaluateKingSafety(normalize_result=True)\n",
    "        self.evaluate_mobility = EvaluateMobility(normalize_result=True)\n",
    "        self.evaluate_pawn_structure = EvaluatePawnStructure(normalize_result=True)\n",
    "        self.evaluate_piece_positions = EvaluatePiecePositions(normalize_result=True)\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the chess board state using various evaluation metrics.\n",
    "\n",
    "        :param state: The current state of the chess game.\n",
    "        :return: A combined heuristic score representing the board evaluation.\n",
    "        \"\"\"\n",
    "        board = state.game_board\n",
    "        # Special handling for endgame phase.\n",
    "        game_over_eval = None\n",
    "        # Assign extreme values for checkmate situations.\n",
    "        if board.is_checkmate():\n",
    "            outcome = board.outcome()\n",
    "            if outcome is not None:\n",
    "                if outcome.winner:\n",
    "                    game_over_eval = float(\"inf\")\n",
    "                else:\n",
    "                    game_over_eval = float(\"-inf\")\n",
    "        # Assign zero for draw situations.\n",
    "        if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "            game_over_eval = 0\n",
    "\n",
    "        if game_over_eval is not None:\n",
    "            return game_over_eval\n",
    "        else:\n",
    "            # Evaluate different aspects of the board.\n",
    "            board_without_king = self.evaluate_board_without_king.h(state)\n",
    "            central_control_score = self.evaluate_central_control_score.h(state)\n",
    "            king_safety = self.evaluate_king_safety.h(state)\n",
    "            mobility = self.evaluate_mobility.h(state)\n",
    "            pawn_structure = self.evaluate_pawn_structure.h(state)\n",
    "            piece_positions = self.evaluate_piece_positions.h(state)\n",
    "            # Optionally print the evaluation scores.\n",
    "            if self.print_evaluation:\n",
    "                print(\"Valutazione: \", board_without_king, central_control_score, king_safety, mobility, pawn_structure,\n",
    "                      piece_positions)\n",
    "            # Combine the scores either using weighted or simple sum approach.\n",
    "            if self.balance_evaluation:\n",
    "                return (\n",
    "                        board_without_king * 0.35 +  # Bilancio del materiale\n",
    "                        central_control_score * 0.20 +  # Controllo del centro\n",
    "                        king_safety * 0.15 +  # Sicurezza del re\n",
    "                        mobility * 0.10 +  # MobilitÃ \n",
    "                        pawn_structure * 0.10 +  # Struttura dei pedoni\n",
    "                        piece_positions * 0.10  # Posizione dei pezzi\n",
    "                )\n",
    "            return (\n",
    "                    board_without_king +\n",
    "                    central_control_score +\n",
    "                    king_safety +\n",
    "                    mobility +\n",
    "                    pawn_structure +\n",
    "                    piece_positions\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da9b55061b03310"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SoftBoardEvaluationChessGame\n",
    "This class provides a more nuanced evaluation of a chess game board by combining various aspects such as material balance, central control, king safety, and piece positions. It offers a more balanced perspective on the chessboard, making it suitable for a comprehensive game analysis.\n",
    "\n",
    "Combined heuristics:\n",
    "   - evaluate_board_without_king: Evaluation component focusing on the board without considering the king's position.\n",
    "   - evaluate_central_control_score: Evaluation component focusing on the control of central squares.\n",
    "   - evaluate_king_safety: Evaluation component focusing on the safety of the king.\n",
    "   - evaluate_piece_positions: Evaluation component focusing on the positions of all pieces except the king."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c6418cf4ad2348f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SoftBoardEvaluationChessGame:\n",
    "    \"\"\"\n",
    "    This class provides a more nuanced evaluation of a chess game board by combining various aspects such\n",
    "    as material balance, central control, king safety, and piece positions. It offers a more balanced\n",
    "    perspective on the chessboard, making it suitable for a comprehensive game analysis.\n",
    "\n",
    "    Attributes:\n",
    "        balance_evaluation (bool): If True, uses a weighted approach for combining different evaluation metrics.\n",
    "        print_evaluation (bool): If True, prints the evaluation scores for debugging or analysis purposes.\n",
    "        evaluate_board_without_king (EvaluateBoardWithoutKing): Component for evaluating the board without considering the king's position.\n",
    "        evaluate_central_control_score (EvaluateCentralControlScore): Component for evaluating central control.\n",
    "        evaluate_king_safety (EvaluateKingSafety): Component for evaluating king safety.\n",
    "        evaluate_piece_positions (EvaluatePiecePositions): Component for evaluating piece positions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, balance_evaluation=True, print_evaluation=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluation components for different aspects of the chess game.\n",
    "\n",
    "        :param balance_evaluation: Indicates whether to use a weighted combination of evaluation metrics.\n",
    "        :param print_evaluation: Indicates whether to print the evaluation scores for each component.\n",
    "        \"\"\"\n",
    "        self.balance_evaluation = balance_evaluation  # Flag for using weighted evaluation scores.\n",
    "        self.print_evaluation = print_evaluation  # Flag for printing the evaluation results.\n",
    "        # Initialize individual evaluation components with normalization.\n",
    "        self.evaluate_board_without_king = EvaluateBoardWithoutKing(normalize_result=True)\n",
    "        self.evaluate_central_control_score = EvaluateCentralControlScore(normalize_result=True)\n",
    "        self.evaluate_king_safety = EvaluateKingSafety(normalize_result=True)\n",
    "        self.evaluate_piece_positions = EvaluatePiecePositions(normalize_result=True)\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the chess board state using a combination of various evaluation metrics.\n",
    "\n",
    "        :param state: The current state of the chess game.\n",
    "        :return: A comprehensive heuristic score representing the board evaluation.\n",
    "        \"\"\"\n",
    "        board = state.game_board\n",
    "        # Handle special game-over conditions like checkmate and stalemate.\n",
    "        game_over_eval = None\n",
    "        if board.is_checkmate():\n",
    "            outcome = board.outcome()\n",
    "            if outcome is not None:\n",
    "                if outcome.winner:\n",
    "                    game_over_eval = float(\"inf\")\n",
    "                else:\n",
    "                    game_over_eval = float(\"-inf\")\n",
    "        if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "            game_over_eval = 0\n",
    "\n",
    "        if game_over_eval is not None:\n",
    "            return game_over_eval\n",
    "        else:\n",
    "            # Calculate individual evaluation scores.\n",
    "            board_without_king = self.evaluate_board_without_king.h(state)\n",
    "            central_control_score = self.evaluate_central_control_score.h(state)\n",
    "            king_safety = self.evaluate_king_safety.h(state)\n",
    "            piece_positions = self.evaluate_piece_positions.h(state)\n",
    "\n",
    "            # Optionally print the evaluation scores.\n",
    "            if self.print_evaluation:\n",
    "                print(\"Valutazione: \", board_without_king, central_control_score, king_safety, piece_positions)\n",
    "\n",
    "            # Combine the scores using weighted or simple sum approach.\n",
    "            if self.balance_evaluation:\n",
    "                return (\n",
    "                        board_without_king * 0.35 +  # Bilancio del materiale\n",
    "                        central_control_score * 0.20 +  # Controllo del centro\n",
    "                        king_safety * 0.25 +  # Sicurezza del re\n",
    "                        piece_positions * 0.20  # Posizione dei pezzi\n",
    "                )\n",
    "            return (\n",
    "                    board_without_king +\n",
    "                    central_control_score +\n",
    "                    king_safety +\n",
    "                    piece_positions\n",
    "            )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.356949100Z",
     "start_time": "2023-10-29T17:06:19.330626700Z"
    }
   },
   "id": "f80d042f3ea3d618"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observation Board\n",
    "\n",
    "This class observes various aspects of a chess game board, offering a comprehensive analysis of material, space, piece activity, direct threats, and specific evaluations from various components like king safety, mobility, pawn structure, and piece positions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83450b13b16ad48f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from .EvaluateBoardWithoutKing import EvaluateBoardWithoutKing\n",
    "from .EvaluateCentralControlScore import EvaluateCentralControlScore\n",
    "from .EvaluateKingSafety import EvaluateKingSafety\n",
    "from .EvaluateMobility import EvaluateMobility\n",
    "from .EvaluatePawnStructure import EvaluatePawnStructure\n",
    "from .EvaluatePiecePositions import EvaluatePiecePositions\n",
    "from .constants import *\n",
    "\n",
    "\n",
    "class ObservationBoard:\n",
    "    \"\"\"\n",
    "    This class observes various aspects of a chess game board, offering a comprehensive analysis of material,\n",
    "    space, piece activity, direct threats.\n",
    "\n",
    "    Attributes:\n",
    "        normalize_result (bool): If true, normalizes the evaluation score within a specific range.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the observation components for different aspects of the chess game.\n",
    "\n",
    "        :param normalize_result: Indicates whether to normalize the evaluation scores.\n",
    "        \"\"\"\n",
    "        self.normalize_result = normalize_result\n",
    "\n",
    "    # 87 microsecondi\n",
    "    def calcola_materiale_totale_spazio_attivita_pezzi_minacce_dirette(self, board):\n",
    "        \"\"\"\n",
    "        Calculates and evaluates several aspects of the chessboard for both players: the total material value,\n",
    "        space control, activity of pieces (excluding pawns), and the number of direct threats (attacked pieces).\n",
    "\n",
    "        :param board: The chess board to be evaluated.\n",
    "        :return: A tuple containing the total material value, space control, piece activity, and direct threats\n",
    "                 for both players (white and black).\n",
    "        \"\"\"\n",
    "        materiale_bianco = 0  # Total material value for white player.\n",
    "        materiale_nero = 0  # Total material value for black player.\n",
    "        spazio_bianco = 0  # Number of squares controlled by white player.\n",
    "        spazio_nero = 0  # Number of squares controlled by black player.\n",
    "        attivita_pezzi_bianco = 0  # Activity of pieces (excluding pawns) for white player.\n",
    "        attivita_pezzi_nero = 0  # Activity of pieces (excluding pawns) for black player.\n",
    "        minacce_dirette_bianco = 0  # Number of white pieces under direct threat.\n",
    "        minacce_dirette_nero = 0  # Number of black pieces under direct threat.\n",
    "\n",
    "        attaccanti_bianco = set()  # Set of squares attacked by white player.\n",
    "        attaccanti_nero = set()  # Set of squares attacked by black player.\n",
    "\n",
    "        # Calculate space control and attackers for each square.\n",
    "        for square in chess.SQUARES:\n",
    "            if board.is_attacked_by(chess.WHITE, square):\n",
    "                spazio_bianco += 1\n",
    "                attaccanti_bianco.add(square)\n",
    "            if board.is_attacked_by(chess.BLACK, square):\n",
    "                spazio_nero += 1\n",
    "                attaccanti_nero.add(square)\n",
    "\n",
    "        # Evaluate material, piece activity, and direct threats.\n",
    "        for square in chess.SQUARES:\n",
    "            pezzo = board.piece_at(square)\n",
    "            if pezzo:\n",
    "                valore = PIECE_VALUE[pezzo.piece_type]  # Value of the piece based on its type.\n",
    "                if pezzo.color == chess.WHITE:\n",
    "                    materiale_bianco += valore\n",
    "                    if square in attaccanti_nero:\n",
    "                        minacce_dirette_bianco += 1\n",
    "                    if pezzo.piece_type != chess.PAWN:\n",
    "                        attivita_pezzi_bianco += len(board.attacks(square))\n",
    "                else:\n",
    "                    materiale_nero += valore\n",
    "                    if square in attaccanti_bianco:\n",
    "                        minacce_dirette_nero += 1\n",
    "                    if pezzo.piece_type != chess.PAWN:\n",
    "                        attivita_pezzi_nero += len(board.attacks(square))\n",
    "\n",
    "        # Return a tuple with the calculated values.\n",
    "        return (materiale_bianco, materiale_nero, spazio_bianco, spazio_nero, attivita_pezzi_bianco,\n",
    "                attivita_pezzi_nero, minacce_dirette_bianco, minacce_dirette_nero)\n",
    "\n",
    "    # 2.55 microsecondi\n",
    "    def calcola_sicurezza_re(self, board):\n",
    "        \"\"\"Calcola la sicurezza del re per ciascun giocatore su una scacchiera di chess.\"\"\"\n",
    "        sicurezza_re_bianco = 0\n",
    "        sicurezza_re_nero = 0\n",
    "\n",
    "        posizione_re_bianco = board.king(chess.WHITE)\n",
    "        posizione_re_nero = board.king(chess.BLACK)\n",
    "\n",
    "        pedone_bianco = chess.Piece(chess.PAWN, chess.WHITE)\n",
    "        pedone_nero = chess.Piece(chess.PAWN, chess.BLACK)\n",
    "\n",
    "        # Direzioni per i pedoni bianchi e neri\n",
    "        direzioni_bianche = [8, 7, 9]  # Nord, Nord-Ovest, Nord-Est\n",
    "        direzioni_nere = [-8, -7, -9]  # Sud, Sud-Est, Sud-Ovest\n",
    "\n",
    "        # Calcolare la sicurezza basandosi sui pedoni circostanti e la posizione\n",
    "        for direzione in direzioni_bianche:\n",
    "            casa_pedone_bianco = posizione_re_bianco + direzione\n",
    "            if casa_pedone_bianco in chess.SQUARES and board.piece_at(casa_pedone_bianco) == pedone_bianco:\n",
    "                sicurezza_re_bianco += 1\n",
    "\n",
    "        for direzione in direzioni_nere:\n",
    "            casa_pedone_nero = posizione_re_nero + direzione\n",
    "            if casa_pedone_nero in chess.SQUARES and board.piece_at(casa_pedone_nero) == pedone_nero:\n",
    "                sicurezza_re_nero += 1\n",
    "\n",
    "        return sicurezza_re_bianco, sicurezza_re_nero\n",
    "\n",
    "    # 6.41 microsecondi\n",
    "    def calcola_controllo_centro(self, board):\n",
    "        \"\"\"\n",
    "        Calculates the control of the board's center by each player. It assesses which player controls\n",
    "        the central squares (D4, E4, D5, E5) and by how much, providing an indication of the central dominance\n",
    "        in the chess game.\n",
    "\n",
    "        :param board: The chess board to be evaluated.\n",
    "        :return: A tuple containing the control of the center score for both the white and black players.\n",
    "        \"\"\"\n",
    "        case_centrali = [chess.D4, chess.E4, chess.D5, chess.E5]  # Central squares of the chessboard.\n",
    "        controllo_centro_bianco = 0  # Control of the center by white player.\n",
    "        controllo_centro_nero = 0  # Control of the center by black player.\n",
    "\n",
    "        # Iterate through each central square to assess control by white and black.\n",
    "        for casa in case_centrali:\n",
    "            attaccanti_bianchi = board.attackers(chess.WHITE, casa)\n",
    "            attaccanti_neri = board.attackers(chess.BLACK, casa)\n",
    "\n",
    "            if attaccanti_bianchi:\n",
    "                controllo_centro_bianco += 1  # Increase score if white controls the square.\n",
    "            if attaccanti_neri:\n",
    "                controllo_centro_nero += 1  # Increase score if black controls the square.\n",
    "\n",
    "        # Return the control scores for white and black players.\n",
    "        return controllo_centro_bianco, controllo_centro_nero\n",
    "\n",
    "    # 3.4 microsecondi\n",
    "    def calcola_mossa_pedoni(self, board):\n",
    "        \"\"\"\n",
    "        Calculates the number of pawns that have moved from their initial position for each player. This metric\n",
    "        gives an insight into the pawn advancement and structure in the game, which is a key aspect of chess strategy.\n",
    "\n",
    "        :param board: The chess board to be evaluated.\n",
    "        :return: A tuple containing the count of moved pawns for both white and black players.\n",
    "        \"\"\"\n",
    "        mossa_pedoni_bianco = 0  # Number of white pawns that have moved from their initial positions.\n",
    "        mossa_pedoni_nero = 0  # Number of black pawns that have moved from their initial positions.\n",
    "\n",
    "        # Iterate through each column to check if pawns have moved from their starting rows.\n",
    "        for colonna in range(8):\n",
    "            # Check for white pawns on the second rank.\n",
    "            casa_iniziale_bianco = chess.square(colonna, 1)\n",
    "            pezzo_bianco = board.piece_at(casa_iniziale_bianco)\n",
    "            if not (pezzo_bianco and pezzo_bianco.piece_type == chess.PAWN and pezzo_bianco.color == chess.WHITE):\n",
    "                mossa_pedoni_bianco += 1\n",
    "\n",
    "            # Check for black pawns on the seventh rank.\n",
    "            casa_iniziale_nero = chess.square(colonna, 6)\n",
    "            pezzo_nero = board.piece_at(casa_iniziale_nero)\n",
    "            if not (pezzo_nero and pezzo_nero.piece_type == chess.PAWN and pezzo_nero.color == chess.BLACK):\n",
    "                mossa_pedoni_nero += 1\n",
    "\n",
    "        # Return the count of moved pawns for both white and black players.\n",
    "        return mossa_pedoni_bianco, mossa_pedoni_nero\n",
    "\n",
    "    # 10.2 microsecondi\n",
    "    def calcola_struttura_pedoni(self, board):\n",
    "        \"\"\"\n",
    "        Calculates a score based on the pawn structure for each player. This evaluation considers aspects like\n",
    "        isolated and doubled pawns, which are crucial for understanding the pawn dynamics and structural weaknesses\n",
    "        or strengths in a chess game.\n",
    "\n",
    "        :param board: The chess board to be evaluated.\n",
    "        :return: A tuple containing the pawn structure score for both the white and black players.\n",
    "        \"\"\"\n",
    "        punteggio_pedoni_bianco = 0  # Score for the pawn structure of white player.\n",
    "        punteggio_pedoni_nero = 0  # Score for the pawn structure of black player.\n",
    "        colonna_pedoni_bianchi = [0] * 8  # Count of white pawns in each column.\n",
    "        colonna_pedoni_neri = [0] * 8  # Count of black pawns in each column.\n",
    "\n",
    "        # Count the number of pawns in each column for each player.\n",
    "        for square in chess.SQUARES:\n",
    "            pezzo = board.piece_at(square)\n",
    "            if pezzo and pezzo.piece_type == chess.PAWN:\n",
    "                colonna = chess.square_file(square)\n",
    "                if pezzo.color == chess.WHITE:\n",
    "                    colonna_pedoni_bianchi[colonna] += 1\n",
    "                else:\n",
    "                    colonna_pedoni_neri[colonna] += 1\n",
    "\n",
    "        # Calculate scores based on isolated and doubled pawns.\n",
    "        for i in range(8):\n",
    "            # Subtract points for doubled pawns.\n",
    "            punteggio_pedoni_bianco -= colonna_pedoni_bianchi[i] if colonna_pedoni_bianchi[i] > 1 else 0\n",
    "            punteggio_pedoni_nero -= colonna_pedoni_neri[i] if colonna_pedoni_neri[i] > 1 else 0\n",
    "\n",
    "            # Subtract points for isolated pawns.\n",
    "            if colonna_pedoni_bianchi[i] > 0:\n",
    "                punteggio_pedoni_bianco -= (i == 0 or colonna_pedoni_bianchi[i - 1] == 0) and (\n",
    "                        i == 7 or colonna_pedoni_bianchi[i + 1] == 0)\n",
    "            if colonna_pedoni_neri[i] > 0:\n",
    "                punteggio_pedoni_nero -= (i == 0 or colonna_pedoni_neri[i - 1] == 0) and (\n",
    "                        i == 7 or colonna_pedoni_neri[i + 1] == 0)\n",
    "\n",
    "        # Return the pawn structure score for both white and black players.\n",
    "        return abs(punteggio_pedoni_bianco), abs(punteggio_pedoni_nero)\n",
    "\n",
    "    # 1.74 microsecondo\n",
    "    def calcola_mossa_pezzi_maggiori(self, board):\n",
    "        \"\"\"\n",
    "        Calculates the number of moves made by major pieces (rooks, bishops, queens) for each player.\n",
    "        This metric assesses how many major pieces have moved from their initial positions,\n",
    "        providing an insight into the player's development and strategy in the game.\n",
    "\n",
    "        :param board: The chess board to be evaluated.\n",
    "        :return: A tuple containing the count of major pieces that have moved for both white and black players.\n",
    "        \"\"\"\n",
    "        mossa_pezzi_maggiori_bianco = 0  # Count of white major pieces that have moved.\n",
    "        mossa_pezzi_maggiori_nero = 0  # Count of black major pieces that have moved.\n",
    "\n",
    "        # Initial positions of major pieces for white player.\n",
    "        posizioni_iniziali_bianco = [chess.A1, chess.B1, chess.C1, chess.D1, chess.E1, chess.F1, chess.G1, chess.H1]\n",
    "        # Initial positions of major pieces for black player.\n",
    "        posizioni_iniziali_nero = [chess.A8, chess.B8, chess.C8, chess.D8, chess.E8, chess.F8, chess.G8, chess.H8]\n",
    "\n",
    "        # Check if major pieces have moved from their initial positions.\n",
    "        for posizione in posizioni_iniziali_bianco:\n",
    "            pezzo = board.piece_at(posizione)\n",
    "            if pezzo is None or (\n",
    "                    pezzo.piece_type != chess.ROOK and pezzo.piece_type != chess.BISHOP and pezzo.piece_type != chess.QUEEN):\n",
    "                mossa_pezzi_maggiori_bianco += 1\n",
    "\n",
    "        for posizione in posizioni_iniziali_nero:\n",
    "            pezzo = board.piece_at(posizione)\n",
    "            if pezzo is None or (\n",
    "                    pezzo.piece_type != chess.ROOK and pezzo.piece_type != chess.BISHOP and pezzo.piece_type != chess.QUEEN):\n",
    "                mossa_pezzi_maggiori_nero += 1\n",
    "\n",
    "        # Return the count of moved major pieces for both white and black players.\n",
    "        return mossa_pezzi_maggiori_bianco, mossa_pezzi_maggiori_nero\n",
    "\n",
    "    # 949 nanosecondo\n",
    "    def calcola_sviluppo_pezzi(self, board):\n",
    "        \"\"\"\n",
    "        Calculates the development of pieces (knights and bishops) for each player. This metric assesses how\n",
    "        many knights and bishops have moved from their initial positions, providing insight into the early\n",
    "        game development and piece activity, which are crucial aspects of chess strategy.\n",
    "\n",
    "        :param board: The chess board to be evaluated.\n",
    "        :return: A tuple containing the count of developed knights and bishops for both white and black players.\n",
    "        \"\"\"\n",
    "        sviluppo_pezzi_bianco = 0  # Count of white knights and bishops that have moved.\n",
    "        sviluppo_pezzi_nero = 0  # Count of black knights and bishops that have moved.\n",
    "\n",
    "        # Initial positions of knights and bishops for white player.\n",
    "        posizioni_iniziali_bianco = [chess.B1, chess.G1, chess.C1, chess.F1]\n",
    "        # Initial positions of knights and bishops for black player.\n",
    "        posizioni_iniziali_nero = [chess.B8, chess.G8, chess.C8, chess.F8]\n",
    "\n",
    "        # Check if knights and bishops have moved from their initial positions.\n",
    "        for posizione in posizioni_iniziali_bianco:\n",
    "            pezzo = board.piece_at(posizione)\n",
    "            if pezzo is None or (pezzo.piece_type != chess.KNIGHT and pezzo.piece_type != chess.BISHOP):\n",
    "                sviluppo_pezzi_bianco += 1\n",
    "\n",
    "        for posizione in posizioni_iniziali_nero:\n",
    "            pezzo = board.piece_at(posizione)\n",
    "            if pezzo is None or (pezzo.piece_type != chess.KNIGHT and pezzo.piece_type != chess.BISHOP):\n",
    "                sviluppo_pezzi_nero += 1\n",
    "\n",
    "        # Return the count of developed knights and bishops for both white and black players.\n",
    "        return sviluppo_pezzi_bianco, sviluppo_pezzi_nero\n",
    "\n",
    "    def __normalize(self, valore, max_val, min_val):\n",
    "        if max_val - min_val == 0:\n",
    "            return 0  # Evita la divisione per zero se min e max sono uguali\n",
    "        return (valore - min_val) / (max_val - min_val)\n",
    "\n",
    "    def h_piccoli(self, board):\n",
    "        \"\"\"\n",
    "        Combines various metrics into a comprehensive array of evaluations for the board. This method\n",
    "        serves as an aggregator that compiles a wide range of metrics from material value to pawn structure,\n",
    "        piece activity, and other specialized evaluations, offering a multifaceted view of the board state.\n",
    "\n",
    "        :param board: The chess board to be evaluated.\n",
    "        :return: An array containing a diverse set of evaluation results.\n",
    "        \"\"\"\n",
    "        risultati = []  # Array to store the results of various evaluations.\n",
    "\n",
    "        # Apply normalization if enabled.\n",
    "        if self.normalize_result:\n",
    "            # Calculate and normalize various metrics.\n",
    "            res = self.calcola_materiale_totale_spazio_attivita_pezzi_minacce_dirette(board)\n",
    "            risultati.append(self.__normalize(res[0], 48, 0))\n",
    "            risultati.append(self.__normalize(res[1], 48, 0))\n",
    "            risultati.append(self.__normalize(res[2], 57, 0))\n",
    "            risultati.append(self.__normalize(res[3], 57, 0))\n",
    "            risultati.append(self.__normalize(res[4], 84, 0))\n",
    "            risultati.append(self.__normalize(res[5], 84, 0))\n",
    "            risultati.append(self.__normalize(res[6], 12, 0))\n",
    "            risultati.append(self.__normalize(res[7], 12, 0))\n",
    "\n",
    "            res = self.calcola_sicurezza_re(board)\n",
    "            risultati.append(self.__normalize(res[0], 4, 0))\n",
    "            risultati.append(self.__normalize(res[1], 4, 0))\n",
    "\n",
    "            res = self.calcola_controllo_centro(board)\n",
    "            risultati.append(self.__normalize(res[0], 5, 0))\n",
    "            risultati.append(self.__normalize(res[1], 5, 0))\n",
    "\n",
    "            res = self.calcola_mossa_pedoni(board)\n",
    "            risultati.append(self.__normalize(res[0], 9, 0))\n",
    "            risultati.append(self.__normalize(res[1], 9, 0))\n",
    "\n",
    "            res = self.calcola_struttura_pedoni(board)\n",
    "            risultati.append(self.__normalize(res[0], 11, 0))\n",
    "            risultati.append(self.__normalize(res[1], 11, 0))\n",
    "\n",
    "            res = self.calcola_mossa_pezzi_maggiori(board)\n",
    "            risultati.append(self.__normalize(res[0], 9, 0))\n",
    "            risultati.append(self.__normalize(res[1], 9, 0))\n",
    "\n",
    "            res = self.calcola_sviluppo_pezzi(board)\n",
    "            risultati.append(self.__normalize(res[0], 5, 0))\n",
    "            risultati.append(self.__normalize(res[1], 5, 0))\n",
    "        else:\n",
    "            # Directly calculate and store the results without normalization.\n",
    "            risultati.extend(self.calcola_materiale_totale_spazio_attivita_pezzi_minacce_dirette(board))\n",
    "            risultati.extend(self.calcola_sicurezza_re(board))\n",
    "            risultati.extend(self.calcola_controllo_centro(board))\n",
    "            risultati.extend(self.calcola_mossa_pedoni(board))\n",
    "            risultati.extend(self.calcola_struttura_pedoni(board))\n",
    "            risultati.extend(self.calcola_mossa_pezzi_maggiori(board))\n",
    "            risultati.extend(self.calcola_sviluppo_pezzi(board))\n",
    "\n",
    "        # Return the resulting array.\n",
    "        return risultati\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8402cd91f831e678"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search Algorithm\n",
    "## MinMaxAlphaBetaPruning\n",
    "Implements the Minimax algorithm with Alpha-Beta pruning for a chess game."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0116240b6156f5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class MinMaxAlphaBetaPruning:\n",
    "    \"\"\"\n",
    "    Implements the Minimax algorithm with Alpha-Beta pruning for a chess game.\n",
    "\n",
    "    Attributes:\n",
    "        game (StateChessGame): The current state of the chess game.\n",
    "        heuristic (function): Heuristic function used to evaluate game states.\n",
    "        max_depth (int): Maximum depth for the Minimax search.\n",
    "        prune_count (int): Count of the number of pruned branches.\n",
    "        eval_count (int): Count of the number of evaluations performed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, heuristic, max_depth=1):\n",
    "        \"\"\"\n",
    "        Initializes the MinMaxAlphaBetaPruning class with a game, heuristic function, and maximum search depth.\n",
    "        :param game: The current state of the chess game.\n",
    "        :param heuristic: Heuristic function used for evaluating game states.\n",
    "        :param max_depth: Maximum depth for the Minimax search. Defaults to 1.\n",
    "        \"\"\"\n",
    "        self.game = game  # The current state of the chess game.\n",
    "        self.heuristic = heuristic  # Heuristic function used to evaluate game states.\n",
    "        self.max_depth = max_depth  # Maximum depth for the Minimax search.\n",
    "        self.prune_count = 0  # Count of the number of pruned branches.\n",
    "        self.eval_count = 0  # Count of the number of evaluations performed.\n",
    "\n",
    "    def pick(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Selects the best state from a list of states based on the player's turn.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        :return: The state with the maximum (or minimum) heuristic value based on the player's turn.\n",
    "        \"\"\"\n",
    "        # If it's the parent's turn, choose the state with the maximum heuristic value.\n",
    "        if parent_turn:\n",
    "            return max(states, key=lambda state: state.h)\n",
    "        # If it's the opponent's turn, choose the state with the minimum heuristic value.\n",
    "        else:\n",
    "            return min(states, key=lambda state: state.h)\n",
    "\n",
    "    def evaluate(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Evaluates a list of states and updates their heuristic values.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        \"\"\"\n",
    "        for state in states:\n",
    "            # If a draw can be claimed in the current state, set heuristic value to 0.0.\n",
    "            if state.game_board.can_claim_draw():\n",
    "                state.h = 0.0\n",
    "            else:\n",
    "                # Otherwise, evaluate the state using the Minimax algorithm with Alpha-Beta pruning.\n",
    "                state.h = self.__minmax_alpha_beta(state, self.max_depth - 1, float(\"-inf\"), float(\"inf\"),\n",
    "                                                   not parent_turn)\n",
    "\n",
    "    def __minmax_alpha_beta(self, state, depth, alpha, beta, turn):\n",
    "        \"\"\"\n",
    "        Private method implementing the Minimax algorithm with Alpha-Beta pruning.\n",
    "\n",
    "        :param state: The current game state.\n",
    "        :param depth: The current depth in the game tree.\n",
    "        :param alpha: The alpha value for Alpha-Beta pruning.\n",
    "        :param beta: The beta value for Alpha-Beta pruning.\n",
    "        :param turn: Flag indicating if it's the maximizing player's turn.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        self.eval_count += 1\n",
    "\n",
    "        # Base case: if maximum depth is reached or the game is over, return the heuristic value of the state.\n",
    "        if depth == 0 or state.game_board.is_game_over():\n",
    "            return self.heuristic.h(state)\n",
    "\n",
    "        # Generate all possible moves (neighbors) from the current state.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "\n",
    "        if turn:  # If it's the maximizing player's turn.\n",
    "            value = float(\"-inf\")\n",
    "            for neighbor in neighbors:\n",
    "                # Recursively call the function to evaluate the neighbor state, updating the value and alpha.\n",
    "                value = max(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, False))\n",
    "                alpha = max(alpha, value)\n",
    "                # Alpha-Beta pruning: if alpha is greater or equal to beta, prune this branch.\n",
    "                if alpha >= beta:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            return value\n",
    "        else:  # If it's the minimizing player's turn.\n",
    "            value = float(\"inf\")\n",
    "            for neighbor in neighbors:\n",
    "                # Similarly, for the minimizing player, update the value and beta.\n",
    "                value = min(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, True))\n",
    "                beta = min(beta, value)\n",
    "                # Alpha-Beta pruning: if beta is less or equal to alpha, prune this branch.\n",
    "                if beta <= alpha:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            return value\n",
    "\n",
    "    def search(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Public method to start the Minimax search with Alpha-Beta pruning from a given state.\n",
    "\n",
    "        :param state: The current state of the chess game.\n",
    "        :return: The best next state for the current player.\n",
    "        \"\"\"\n",
    "        # Generate all possible moves (neighbors) from the current state.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "        # Evaluate the neighbors to update their heuristic values.\n",
    "        self.evaluate(neighbors, state.game_board.turn)\n",
    "        # Choose the best move based on the current player's turn.\n",
    "        return self.pick(neighbors, state.game_board.turn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.415337200Z",
     "start_time": "2023-10-29T17:06:19.391615400Z"
    }
   },
   "id": "15ea252b8546ba0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MinMaxAlphaBetaPruningH0Cut\n",
    "Extends the Minimax algorithm with Alpha-Beta pruning for a chess game, incorporating an h0 cutoff heuristic."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5fc9a3644ab8a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MinMaxAlphaBetaPruningH0Cut:\n",
    "    \"\"\"\n",
    "    Extends the Minimax algorithm with Alpha-Beta pruning for a chess game, incorporating an h0 cutoff heuristic.\n",
    "\n",
    "    Attributes:\n",
    "        game (StateChessGame): The current state of the chess game.\n",
    "        heuristic (function): Main heuristic function for evaluating game states.\n",
    "        h0_cut (function): Secondary heuristic function used for h0 cutoff.\n",
    "        k (int): Number of states to consider after applying the h0 cutoff.\n",
    "        max_depth (int): Maximum depth for the Minimax search.\n",
    "        prune_count (int): Count of pruned branches in the main search.\n",
    "        eval_count (int): Count of evaluations in the main search.\n",
    "        eval_h0_cut_count (int): Count of evaluations for the h0 cutoff.\n",
    "        prune_h0_cut_count (int): Count of pruned branches due to the h0 cutoff.\n",
    "        memoization (dict): Dictionary for memoization to store previously calculated states.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, heuristic, h0_cut, k=5, max_depth=1):\n",
    "        \"\"\"\n",
    "        Initializes the MinMaxAlphaBetaPruningH0Cut class with game settings, heuristics, and search parameters.\n",
    "\n",
    "        :param game: The current state of the chess game.\n",
    "        :param heuristic: Main heuristic function used for evaluating game states.\n",
    "        :param h0_cut: Secondary heuristic function used for h0 cutoff.\n",
    "        :param k: Number of states to consider after applying the h0 cutoff. Defaults to 5.\n",
    "        :param max_depth: Maximum depth for the Minimax search. Defaults to 1.\n",
    "        \"\"\"\n",
    "        self.game = game  # The current state of the chess game.\n",
    "        self.heuristic = heuristic  # Main heuristic function used to evaluate game states.\n",
    "        self.h0_cut = h0_cut  # Secondary heuristic used for the h0 cutoff.\n",
    "        self.k = k  # Number of states to consider after applying the h0 cutoff.\n",
    "        self.max_depth = max_depth  # Maximum depth for the Minimax search.\n",
    "        self.prune_count = 0  # Count of pruned branches in the main search.\n",
    "        self.eval_count = 0  # Count of evaluations in the main search.\n",
    "        self.eval_h0_cut_count = 0  # Count of evaluations for the h0 cutoff.\n",
    "        self.prune_h0_cut_count = 0  # Count of pruned branches due to the h0 cutoff.\n",
    "        self.memoization = {}  # Dictionary for storing previously calculated states.\n",
    "\n",
    "    def pick(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Selects the best state based on the player's turn.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        :return: The state with the maximum (or minimum) heuristic value based on the player's turn.\n",
    "        \"\"\"\n",
    "        # Choose the state with the maximum or minimum heuristic value depending on the player's turn.\n",
    "        if parent_turn:\n",
    "            return max(states, key=lambda state: state.h)\n",
    "        else:\n",
    "            return min(states, key=lambda state: state.h)\n",
    "\n",
    "    def evaluate(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Evaluates a list of states and updates their heuristic values.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        \"\"\"\n",
    "        for state in states:\n",
    "            # If a draw can be claimed, set heuristic value to 0.0.\n",
    "            if state.game_board.can_claim_draw():\n",
    "                state.h = 0.0\n",
    "            else:\n",
    "                # Otherwise, evaluate using the Minimax algorithm with Alpha-Beta pruning.\n",
    "                state.h = self.__minmax_alpha_beta(state, self.max_depth - 1, float(\"-inf\"), float(\"inf\"),\n",
    "                                                   not parent_turn)\n",
    "\n",
    "    def __minmax_alpha_beta(self, state, depth, alpha, beta, turn):\n",
    "        \"\"\"\n",
    "        Private method implementing the Minimax algorithm with Alpha-Beta pruning and memoization.\n",
    "\n",
    "        :param state: The current game state.\n",
    "        :param depth: The current depth in the game tree.\n",
    "        :param alpha: The alpha value for Alpha-Beta pruning.\n",
    "        :param beta: The beta value for Alpha-Beta pruning.\n",
    "        :param turn: Flag indicating if it's the maximizing player's turn.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        self.eval_count += 1\n",
    "\n",
    "        # Check if the state is already evaluated and stored in memoization.\n",
    "        if (state, depth, turn) in self.memoization:\n",
    "            return self.memoization[(state, depth, turn)]\n",
    "\n",
    "        # Base case: if maximum depth is reached or the game is over, return the heuristic value.\n",
    "        if depth == 0 or state.game_board.is_game_over():\n",
    "            return self.heuristic.h(state)\n",
    "\n",
    "        # Generate possible moves (neighbors), applying the h0 cutoff.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "        top_neighbors = self.__h0_cut(neighbors, state.game_board.turn)\n",
    "\n",
    "        if turn:  # Maximizing player's turn.\n",
    "            value = float(\"-inf\")\n",
    "            for neighbor in top_neighbors:\n",
    "                # Recursively evaluate the state, update value and alpha.\n",
    "                value = max(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, False))\n",
    "                alpha = max(alpha, value)\n",
    "                # Alpha-Beta pruning: prune if alpha >= beta.\n",
    "                if alpha >= beta:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            self.memoization[(state, depth, turn)] = value\n",
    "            return value\n",
    "        else:  # Minimizing player's turn.\n",
    "            value = float(\"inf\")\n",
    "            for neighbor in top_neighbors:\n",
    "                # Similar evaluation for the minimizing player.\n",
    "                value = min(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, True))\n",
    "                beta = min(beta, value)\n",
    "                # Prune if beta <= alpha.\n",
    "                if beta <= alpha:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            self.memoization[(state, depth, turn)] = value\n",
    "            return value\n",
    "\n",
    "    def __h0_cut(self, states, turn):\n",
    "        \"\"\"\n",
    "        Applies the h0 cutoff heuristic to limit the number of states considered.\n",
    "\n",
    "        :param states: A list of game states.\n",
    "        :param turn: Flag indicating the current player's turn.\n",
    "        :return: A list of states after applying the h0 cutoff.\n",
    "        \"\"\"\n",
    "        initial_count = len(states)\n",
    "        # Evaluate states using the h0 heuristic and count evaluations.\n",
    "        for state in states:\n",
    "            state.h0 = self.h0_cut.h(state)\n",
    "            self.eval_h0_cut_count += 1\n",
    "\n",
    "        # Sort and select the top k states based on the h0 heuristic value.\n",
    "        sorted_states = sorted(states, key=lambda state: state.h0, reverse=turn)[:self.k]\n",
    "        # Count how many states were pruned by this process.\n",
    "        self.prune_h0_cut_count += initial_count - len(sorted_states)\n",
    "\n",
    "        return sorted_states\n",
    "\n",
    "    def search(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Public method to start the search with Alpha-Beta pruning and h0 cutoff.\n",
    "\n",
    "        :param state: The current state of the chess game.\n",
    "        :return: The best next state for the current player.\n",
    "        \"\"\"\n",
    "        # Generate possible moves, applying the h0 cutoff.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "        top_neighbors = self.__h0_cut(neighbors, state.game_board.turn)\n",
    "        # Evaluate the top neighbors and choose the best move based on the player's turn.\n",
    "        self.evaluate(top_neighbors, state.game_board.turn)\n",
    "        return self.pick(top_neighbors, state.game_board.turn)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b86ad39811f4ece"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MinMaxAlphaBetaPruningHlCut\n",
    "\n",
    "Extends the Minimax algorithm with Alpha-Beta pruning for a chess game, incorporating h0 and hl cutoff heuristics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a37bee8d529bd02c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MinMaxAlphaBetaPruningHlCut:\n",
    "    \"\"\"\n",
    "    Extends the Minimax algorithm with Alpha-Beta pruning for a chess game, incorporating h0 and hl cutoff heuristics.\n",
    "\n",
    "    Attributes:\n",
    "        game (StateChessGame): The current state of the chess game.\n",
    "        heuristic (function): Main heuristic function for evaluating game states.\n",
    "        h0_cut (function): Heuristic function used for the h0 cutoff.\n",
    "        k (int): Number of states to consider after applying the h0 and hl cutoffs.\n",
    "        l (int): Depth for the hl cutoff calculation.\n",
    "        max_depth (int): Maximum depth for the Minimax search.\n",
    "        prune_count (int): Count of pruned branches in the main search.\n",
    "        eval_count (int): Count of evaluations in the main search.\n",
    "        eval_h0_cut_count (int): Count of evaluations for the h0 cutoff.\n",
    "        prune_h0_cut_count (int): Count of pruned branches due to the h0 cutoff.\n",
    "        eval_hl_cut_count (int): Count of evaluations for the hl cutoff.\n",
    "        prune_hl_cut_count (int): Count of pruned branches due to the hl cutoff.\n",
    "        memoization (dict): Dictionary for memoization to store previously calculated states.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, heuristic, h0_cut, k=5, l=3, max_depth=1):\n",
    "        \"\"\"\n",
    "        Initializes the MinMaxAlphaBetaPruningHlCut class with game settings, heuristics, and search parameters.\n",
    "\n",
    "        :param game: The current state of the chess game.\n",
    "        :param heuristic: Main heuristic function used for evaluating game states.\n",
    "        :param h0_cut: Heuristic function used for the h0 cutoff.\n",
    "        :param k: Number of states to consider after applying the h0 and hl cutoffs. Defaults to 5.\n",
    "        :param l: Depth for the hl cutoff calculation. Defaults to 3.\n",
    "        :param max_depth: Maximum depth for the Minimax search. Defaults to 1.\n",
    "        \"\"\"\n",
    "        self.game = game  # The current state of the chess game.\n",
    "        self.heuristic = heuristic  # Main heuristic function for evaluating game states.\n",
    "        self.h0_cut = h0_cut  # Heuristic function used for the h0 cutoff.\n",
    "        self.k = k  # Number of states to consider after applying the h0 and hl cutoffs.\n",
    "        self.l = l  # Depth for the hl cutoff calculation.\n",
    "        self.max_depth = max_depth  # Maximum depth for the Minimax search.\n",
    "        self.prune_count = 0  # Count of pruned branches in the main search.\n",
    "        self.eval_count = 0  # Count of evaluations in the main search.\n",
    "        self.eval_h0_cut_count = 0  # Count of evaluations for the h0 cutoff.\n",
    "        self.prune_h0_cut_count = 0  # Count of pruned branches due to the h0 cutoff.\n",
    "        self.eval_hl_cut_count = 0  # Count of evaluations for the hl cutoff.\n",
    "        self.prune_hl_cut_count = 0  # Count of pruned branches due to the hl cutoff.\n",
    "        self.memoization = {}  # Dictionary for storing previously calculated states.\n",
    "\n",
    "    def pick(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Selects the best state based on the player's turn.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        :return: The state with the maximum (or minimum) heuristic value based on the player's turn.\n",
    "        \"\"\"\n",
    "        # Choose the state with the maximum or minimum heuristic value depending on the player's turn.\n",
    "        if parent_turn:\n",
    "            return max(states, key=lambda state: state.h)\n",
    "        else:\n",
    "            return min(states, key=lambda state: state.h)\n",
    "\n",
    "    def evaluate(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Evaluates a list of states and updates their heuristic values.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        \"\"\"\n",
    "        for state in states:\n",
    "            # If a draw can be claimed, set heuristic value to 0.0.\n",
    "            if state.game_board.can_claim_draw():\n",
    "                state.h = 0.0\n",
    "            else:\n",
    "                # Evaluate using the Minimax algorithm with Alpha-Beta pruning.\n",
    "                state.h = self.__minmax_alpha_beta(state, self.max_depth - 1, float(\"-inf\"), float(\"inf\"),\n",
    "                                                   not parent_turn)\n",
    "\n",
    "    # Private method implementing the Minimax algorithm with Alpha-Beta pruning and memoization.\n",
    "    def __minmax_alpha_beta(self, state, depth, alpha, beta, turn):\n",
    "        \"\"\"\n",
    "        Private method implementing the Minimax algorithm with Alpha-Beta pruning and memoization.\n",
    "\n",
    "        :param state: The current game state.\n",
    "        :param depth: The current depth in the game tree.\n",
    "        :param alpha: The alpha value for Alpha-Beta pruning.\n",
    "        :param beta: The beta value for Alpha-Beta pruning.\n",
    "        :param turn: Flag indicating if it's the maximizing player's turn.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        self.eval_count += 1\n",
    "\n",
    "        # Check if the state is already evaluated and stored in memoization.\n",
    "        if (state, depth, turn) in self.memoization:\n",
    "            return self.memoization[(state, depth, turn)]\n",
    "\n",
    "        # Base case: if maximum depth is reached or the game is over, return the heuristic value.\n",
    "        if depth == 0 or state.game_board.is_game_over():\n",
    "            return self.heuristic.h(state)\n",
    "\n",
    "        # Generate possible moves (neighbors), applying the h0 cutoff.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "        top_neighbors = self.__h0_cut(neighbors, state.game_board.turn)\n",
    "\n",
    "        if turn:  # Maximizing player's turn.\n",
    "            value = float(\"-inf\")\n",
    "            for neighbor in top_neighbors:\n",
    "                # Recursively evaluate the state, update value and alpha.\n",
    "                value = max(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, False))\n",
    "                alpha = max(alpha, value)\n",
    "                # Alpha-Beta pruning: prune if alpha >= beta.\n",
    "                if alpha >= beta:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            self.memoization[(state, depth, turn)] = value\n",
    "            return value\n",
    "        else:  # Minimizing player's turn.\n",
    "            value = float(\"inf\")\n",
    "            for neighbor in top_neighbors:\n",
    "                # Similar evaluation for the minimizing player.\n",
    "                value = min(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, True))\n",
    "                beta = min(beta, value)\n",
    "                # Prune if beta <= alpha.\n",
    "                if beta <= alpha:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            self.memoization[(state, depth, turn)] = value\n",
    "            return value\n",
    "\n",
    "    def __h0_cut(self, states, turn):\n",
    "        \"\"\"\n",
    "        Applies the h0 cutoff heuristic to limit the number of states considered.\n",
    "\n",
    "        :param states: A list of game states.\n",
    "        :param turn: Flag indicating the current player's turn.\n",
    "        :return: A list of states after applying the h0 cutoff.\n",
    "        \"\"\"\n",
    "        initial_count = len(states)\n",
    "        # Evaluate states using the h0 heuristic and count evaluations.\n",
    "        for state in states:\n",
    "            state.h0 = self.h0_cut.h(state)\n",
    "            self.eval_h0_cut_count += 1\n",
    "\n",
    "        # Sort and select the top k states based on the h0 heuristic value.\n",
    "        sorted_states = sorted(states, key=lambda state: state.h0, reverse=turn)[:self.k]\n",
    "        # Count how many states were pruned by this process.\n",
    "        self.prune_h0_cut_count += initial_count - len(sorted_states)\n",
    "\n",
    "        return sorted_states\n",
    "\n",
    "    def __hl_cut(self, states, turn):\n",
    "        \"\"\"\n",
    "        Applies the hl cutoff heuristic to further limit the number of states considered.\n",
    "\n",
    "        :param states: A list of game states.\n",
    "        :param turn: Flag indicating the current player's turn.\n",
    "        :return: A list of states after applying the hl cutoff.\n",
    "        \"\"\"\n",
    "        initial_count = len(states)\n",
    "        # Evaluate states using a deeper level of the Minimax algorithm (hl cutoff).\n",
    "        for state in states:\n",
    "            state.hl = self.__minmax_alpha_beta_hl(state, self.l - 1, float(\"-inf\"), float(\"inf\"), not turn)\n",
    "        # Sort and select the top k states based on the hl heuristic value.\n",
    "        sorted_states = sorted(states, key=lambda state: state.hl, reverse=turn)[:self.k]\n",
    "        # Count how many states were pruned by this process.\n",
    "        self.prune_hl_cut_count += initial_count - len(sorted_states)\n",
    "        return sorted_states\n",
    "\n",
    "    def __minmax_alpha_beta_hl(self, state, depth, alpha, beta, turn):\n",
    "        \"\"\"\n",
    "        Implements a deeper level of the Minimax algorithm for the hl cutoff.\n",
    "\n",
    "        :param state: The current game state.\n",
    "        :param depth: The current depth in the game tree.\n",
    "        :param alpha: The alpha value for Alpha-Beta pruning.\n",
    "        :param beta: The beta value for Alpha-Beta pruning.\n",
    "        :param turn: Flag indicating if it's the maximizing player's turn.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        self.eval_hl_cut_count += 1\n",
    "\n",
    "        # Base case: if maximum depth is reached or the game is over, return the heuristic value from h0_cut.\n",
    "        if depth == 0 or state.game_board.is_game_over():\n",
    "            return self.h0_cut.h(state)\n",
    "\n",
    "        neighbors = self.game.neighbors(state)\n",
    "\n",
    "        if turn:  # Maximizing player's turn.\n",
    "            value = float(\"-inf\")\n",
    "            for neighbor in neighbors:\n",
    "                # Recursively evaluate the state for hl cutoff, update value and alpha.\n",
    "                value = max(value, self.__minmax_alpha_beta_hl(neighbor, depth - 1, alpha, beta, False))\n",
    "                alpha = max(alpha, value)\n",
    "                # Alpha-Beta pruning for hl cutoff.\n",
    "                if alpha >= beta:\n",
    "                    self.prune_hl_cut_count += 1\n",
    "                    break\n",
    "            return value\n",
    "        else:  # Minimizing player's turn.\n",
    "            value = float(\"inf\")\n",
    "            for neighbor in neighbors:\n",
    "                # Similar evaluation for the minimizing player for hl cutoff.\n",
    "                value = min(value, self.__minmax_alpha_beta_hl(neighbor, depth - 1, alpha, beta, True))\n",
    "                beta = min(beta, value)\n",
    "                # Prune if beta <= alpha in hl cutoff.\n",
    "                if beta <= alpha:\n",
    "                    self.prune_hl_cut_count += 1\n",
    "                    break\n",
    "            return value\n",
    "\n",
    "    def search(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Public method to start the search with Alpha-Beta pruning, h0, and hl cutoffs.\n",
    "\n",
    "        :param state: The current state of the chess game.\n",
    "        :return: The best next state for the current player.\n",
    "        \"\"\"\n",
    "        # Generate possible moves, applying the hl cutoff.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "        top_neighbors = self.__hl_cut(neighbors, state.game_board.turn)\n",
    "        # Evaluate the top neighbors and choose the best move based on the player's turn.\n",
    "        self.evaluate(top_neighbors, state.game_board.turn)\n",
    "        return self.pick(top_neighbors, state.game_board.turn)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e51aec030ac5623"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MinMaxAlphaBetaPruningHrCut\n",
    "\n",
    "Implements the Minimax algorithm with Alpha-Beta pruning for a chess game, incorporating a machine learning-based heuristic evaluation (hr cut)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a51c6ca35d734f26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from chessgame import StateChessGame\n",
    "from chessgame.heuristics.ObservationBoard import ObservationBoard\n",
    "\n",
    "\n",
    "class MinMaxAlphaBetaPruningHrCut:\n",
    "    \"\"\"\n",
    "    Implements the Minimax algorithm with Alpha-Beta pruning for a chess game, incorporating a machine learning-based heuristic evaluation (hr cut).\n",
    "\n",
    "    Attributes:\n",
    "        game (StateChessGame): The current state of the chess game.\n",
    "        heuristic (function): Main heuristic function used to evaluate game states.\n",
    "        k (int): Number of states to consider after applying the hr (regressor) cutoff.\n",
    "        max_depth (int): Maximum depth for the Minimax search.\n",
    "        prune_count (int): Count of pruned branches in the main search.\n",
    "        eval_count (int): Count of evaluations in the main search.\n",
    "        eval_hr_cut_count (int): Count of evaluations for the hr cutoff.\n",
    "        prune_hr_cut_count (int): Count of pruned branches due to the hr cutoff.\n",
    "        memoization (dict): Dictionary for storing previously calculated states.\n",
    "        mlp_regressor (joblib model): Loaded machine learning model for regression.\n",
    "        observation (ObservationBoard): Observation board for normalizing results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, heuristic, k=5, max_depth=1):\n",
    "        \"\"\"\n",
    "        Initializes the MinMaxAlphaBetaPruningHrCut class with game settings, heuristics, and search parameters.\n",
    "\n",
    "        :param game: The current state of the chess game.\n",
    "        :param heuristic: Main heuristic function used for evaluating game states.\n",
    "        :param k: Number of states to consider after applying the hr cutoff. Defaults to 5.\n",
    "        :param max_depth: Maximum depth for the Minimax search. Defaults to 1.\n",
    "        \"\"\"\n",
    "        self.game = game  # The current state of the chess game.\n",
    "        self.heuristic = heuristic  # Main heuristic function used to evaluate game states.\n",
    "        self.k = k  # Number of states to consider after applying the h0 cutoff.\n",
    "        self.max_depth = max_depth  # Maximum depth for the Minimax search.\n",
    "        self.prune_count = 0  # Count of pruned branches in the main search.\n",
    "        self.eval_count = 0  # Count of evaluations in the main search.\n",
    "        self.eval_hr_cut_count = 0  # Count of evaluations for the h0 cutoff.\n",
    "        self.prune_hr_cut_count = 0  # Count of pruned branches due to the h0 cutoff.\n",
    "        self.memoization = {}  # Dictionary for storing previously calculated states.\n",
    "        self.mlp_regressor = joblib.load('./chessgame/mlp_regressor_model.joblib')  # Load the ML regressor model.\n",
    "        self.observation = ObservationBoard(normalize_result=True)  # Initialize the observation board.\n",
    "\n",
    "    def pick(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Selects the best state from a list of states based on the player's turn.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        :return: The state with the maximum (or minimum) heuristic value based on the player's turn.\n",
    "        \"\"\"\n",
    "        # Choose the state with the maximum or minimum heuristic value depending on the player's turn.\n",
    "        if parent_turn:\n",
    "            return max(states, key=lambda state: state.h)\n",
    "        else:\n",
    "            return min(states, key=lambda state: state.h)\n",
    "\n",
    "    def evaluate(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Evaluates a list of states and updates their heuristic values.\n",
    "\n",
    "        :param states: A list of game states to evaluate.\n",
    "        :param parent_turn: A flag indicating if it's the parent player's turn.\n",
    "        \"\"\"\n",
    "        for state in states:\n",
    "            # If a draw can be claimed, set heuristic value to 0.0.\n",
    "            if state.game_board.can_claim_draw():\n",
    "                state.h = 0.0\n",
    "            else:\n",
    "                # Otherwise, evaluate using the Minimax algorithm with Alpha-Beta pruning.\n",
    "                state.h = self.__minmax_alpha_beta(state, self.max_depth - 1, float(\"-inf\"), float(\"inf\"),\n",
    "                                                   not parent_turn)\n",
    "\n",
    "    def __minmax_alpha_beta(self, state, depth, alpha, beta, turn):\n",
    "        \"\"\"\n",
    "        Private method implementing the Minimax algorithm with Alpha-Beta pruning.\n",
    "\n",
    "        :param state: The current game state.\n",
    "        :param depth: The current depth in the game tree.\n",
    "        :param alpha: The alpha value for Alpha-Beta pruning.\n",
    "        :param beta: The beta value for Alpha-Beta pruning.\n",
    "        :param turn: Flag indicating if it's the maximizing player's turn.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        self.eval_count += 1\n",
    "\n",
    "        # Check if the state is already evaluated and stored in memoization.\n",
    "        if (state, depth, turn) in self.memoization:\n",
    "            return self.memoization[(state, depth, turn)]\n",
    "\n",
    "        # Base case: if maximum depth is reached or the game is over, return the heuristic value.\n",
    "        if depth == 0 or state.game_board.is_game_over():\n",
    "            return self.heuristic.h(state)\n",
    "\n",
    "        # Generate possible moves (neighbors), applying the hr cutoff.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "        top_neighbors = self.__hr_cut(neighbors, state.game_board.turn)\n",
    "\n",
    "        if turn:  # Maximizing player's turn.\n",
    "            value = float(\"-inf\")\n",
    "            for neighbor in top_neighbors:\n",
    "                # Recursively evaluate the state, update value and alpha.\n",
    "                value = max(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, False))\n",
    "                alpha = max(alpha, value)\n",
    "                # Alpha-Beta pruning: prune if alpha >= beta.\n",
    "                if alpha >= beta:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            self.memoization[(state, depth, turn)] = value\n",
    "            return value\n",
    "        else:  # Minimizing player's turn.\n",
    "            value = float(\"inf\")\n",
    "            for neighbor in top_neighbors:\n",
    "                # Similar evaluation for the minimizing player.\n",
    "                value = min(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, True))\n",
    "                beta = min(beta, value)\n",
    "                # Prune if beta <= alpha.\n",
    "                if beta <= alpha:\n",
    "                    self.prune_count += 1\n",
    "                    break\n",
    "            self.memoization[(state, depth, turn)] = value\n",
    "            return value\n",
    "\n",
    "    def __hr_cut(self, states, turn):\n",
    "        \"\"\"\n",
    "        Applies the hr cutoff using the ML regressor to limit the number of states considered.\n",
    "\n",
    "        :param states: A list of game states.\n",
    "        :param turn: Flag indicating the current player's turn.\n",
    "        :return: A list of states after applying the hr cutoff.\n",
    "        \"\"\"\n",
    "        initial_count = len(states)\n",
    "\n",
    "        for state in states:\n",
    "            observations = self.observation.h_piccoli(state.game_board)  # Get observations from the board.\n",
    "            state.hr = self.__regressor_eval(observations)  # Evaluate state using the ML regressor.\n",
    "            self.eval_hr_cut_count += 1\n",
    "\n",
    "        # Sort and select the top k states based on the hr value.\n",
    "        sorted_states = sorted(states, key=lambda state: state.hr, reverse=turn)[:self.k]\n",
    "        # Count how many states were pruned by this process.\n",
    "        self.prune_hr_cut_count += initial_count - len(sorted_states)\n",
    "\n",
    "        return sorted_states\n",
    "\n",
    "    def __regressor_eval(self, observations):\n",
    "        \"\"\"\n",
    "        Evaluates a state using the ML regressor.\n",
    "\n",
    "        :param observations: The observations extracted from the chess board.\n",
    "        :return: The predicted value from the ML regressor.\n",
    "        \"\"\"\n",
    "        colonne = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8', 'h9', 'h10',\n",
    "                   'h11', 'h12', 'h13', 'h14', 'h15', 'h16', 'h17', 'h18', 'h19',\n",
    "                   'h20']\n",
    "        df = pd.DataFrame([observations], columns=colonne)\n",
    "        return self.mlp_regressor.predict(df)[0]  # Predict and return the first value.\n",
    "\n",
    "    def search(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Public method to start the search with Alpha-Beta pruning and hr cutoff.\n",
    "\n",
    "        :param state: The current state of the chess game.\n",
    "        :return: The best next state for the current player.\n",
    "        \"\"\"\n",
    "        # Generate possible moves, applying the h0 cutoff.\n",
    "        neighbors = self.game.neighbors(state)\n",
    "        top_neighbors = self.__hr_cut(neighbors, state.game_board.turn)\n",
    "        # Evaluate the top neighbors and choose the best move based on the player's turn.\n",
    "        self.evaluate(top_neighbors, state.game_board.turn)\n",
    "        return self.pick(top_neighbors, state.game_board.turn)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1262c54b65557132"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Method Main"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a6bdd6a71c26e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The game of chess begins!\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . N . .\n",
      "P P P P P P P P\n",
      "R N B Q K B . R\n",
      "Agent 1 (WHITE) played the move: g1f3\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . .\n",
      ". . . . . N . .\n",
      "P P P P P P P P\n",
      "R N B Q K B . R\n",
      "Agent 2 (BLACK) played the move: d7d5\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . P\n",
      ". . . . . N . .\n",
      "P P P P P P P .\n",
      "R N B Q K B . R\n",
      "Agent 1 (WHITE) played the move: h2h4\n",
      "r n . q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . P\n",
      ". . . . . N . b\n",
      "P P P P P P P .\n",
      "R N B Q K B . R\n",
      "Agent 2 (BLACK) played the move: c8h3\n",
      "r n . q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . P\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 1 (WHITE) played the move: h1h3\n",
      "r n . q k b n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . p .\n",
      ". . . . . . . P\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 2 (BLACK) played the move: g7g5\n",
      "r n . q k b n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . P .\n",
      ". . . . . . . .\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 1 (WHITE) played the move: h4g5\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . b\n",
      ". . . p . . P .\n",
      ". . . . . . . .\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 2 (BLACK) played the move: f8h6\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . b\n",
      ". . . p . . P .\n",
      ". . . . . . . .\n",
      ". . N . . N . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: b1c3\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . b .\n",
      ". . . . . . . .\n",
      ". . N . . N . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: h6g5\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: f3g5\n",
      "r n . q k . . r\n",
      "p p p . p p . p\n",
      ". . . . . . . n\n",
      ". . . p . . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: g8h6\n",
      "r n . q k . . r\n",
      "p p p . p p . p\n",
      ". . . . . . . n\n",
      ". . . p . . N .\n",
      ". . . . . . . .\n",
      ". . N . R . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: h3e3\n",
      "r n . q k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p p . N .\n",
      ". . . . . . . .\n",
      ". . N . R . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: e7e5\n",
      "r n . q k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p R . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: e3e5\n",
      "\n",
      "r n . . k . . r\n",
      "p p p . q p . p\n",
      ". . . . . . . n\n",
      ". . . p R . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: d8e7\n",
      "r n . . k . . r\n",
      "p p p . q p . p\n",
      ". . . . . . . n\n",
      ". . . p R . . .\n",
      ". . . . . . . .\n",
      ". . N . . N . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: g5f3\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p q . . .\n",
      ". . . . . . . .\n",
      ". . N . . N . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: e7e5\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p q . . .\n",
      ". . . . P . . .\n",
      ". . N . . N . .\n",
      "P P P P . P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: e2e4\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p . . . .\n",
      ". . . . P . . .\n",
      ". . q . . N . .\n",
      "P P P P . P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: e5c3\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: d2c3\n",
      "r . . . k . . r\n",
      "p p p . . p . p\n",
      "n . . . . . . n\n",
      ". . . p . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: b8a6\n",
      "r . . . k . . r\n",
      "p p p . . p . p\n",
      "n . . . . . . n\n",
      ". . . Q . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 1 (WHITE) played the move: d1d5\n",
      ". . . r k . . r\n",
      "p p p . . p . p\n",
      "n . . . . . . n\n",
      ". . . Q . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 2 (BLACK) played the move: a8d8\n",
      ". . . r k . . r\n",
      "p p p . . p . p\n",
      "n . . . Q . . n\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 1 (WHITE) played the move: d5e6\n",
      "\n",
      ". . . r k . . r\n",
      "p p p . . . . p\n",
      "n . . . p . . n\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 2 (BLACK) played the move: f7e6\n",
      ". . . r k . . r\n",
      "p p p . . . . p\n",
      "n . . . p . . n\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K . . .\n",
      "Agent 1 (WHITE) played the move: f1b5\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . p . . n\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K . . .\n",
      "Agent 2 (BLACK) played the move: d8d7\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . p . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: c1h6\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . p . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e6e5\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: f3e5\n",
      ". . . . k r . .\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h8f8\n",
      ". . . . k r . .\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e5f7\n",
      ". . . . k . . r\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: f8h8\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: f7e5\n",
      ". . . . k r . .\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h8f8\n",
      ". . . . k r . .\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e5f7\n",
      ". . . . k . . r\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: f8h8\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: f7g5\n",
      ". . . . k r . .\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h8f8\n",
      ". . . . k B . .\n",
      "p p p r . . . p\n",
      "n . . . . . . .\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: h6f8\n",
      ". . . . . k . .\n",
      "p p p r . . . p\n",
      "n . . . . . . .\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e8f8\n",
      ". . . . . k . .\n",
      "p p p r . . . p\n",
      "n . . . N . . .\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: g5e6\n",
      "\n",
      ". . . . . . . .\n",
      "p p p r k . . p\n",
      "n . . . N . . .\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: f8e7\n",
      ". . . . . . . .\n",
      "p p p r k . . p\n",
      "n . . . . . . .\n",
      ". B . . . . . .\n",
      ". . . N P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e6d4\n",
      ". . . . . . . .\n",
      "p p p . k . . p\n",
      "n . . . . . . .\n",
      ". B . . . . . .\n",
      ". . . r P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: d7d4\n",
      ". . . . . . . .\n",
      "p p p . k . . p\n",
      "n . . . . . . .\n",
      ". B . . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: c3d4\n",
      ". . . . . . . .\n",
      "p p . . k . . p\n",
      "n . . . . . . .\n",
      ". B p . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: c7c5\n",
      ". . . . . . . .\n",
      "p p . . k . . p\n",
      "n . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . B P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: b5e2\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . p . . . . p\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . B P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h7h5\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . p . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e2h5\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . p P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: c5d4\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . p P . . .\n",
      "P . . . . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: a2a3\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". n . p P . . .\n",
      "P . . . . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: a6b4\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". P . p P . . .\n",
      ". . . . . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: a3b4\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". P . . P . . .\n",
      ". . . p . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: d4d3\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". P . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: c2d3\n",
      ". . . . . . . .\n",
      ". p . . k . . .\n",
      ". . . . . . . .\n",
      "p . . . . . . B\n",
      ". P . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: a7a5\n",
      ". . . . . . . .\n",
      ". p . . k . . .\n",
      ". . . . . . . .\n",
      "P . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: b4a5\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". p . . . . . .\n",
      "P . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: b7b6\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". P . . . . . .\n",
      ". . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: a5b6\n",
      "\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e7e6\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: d3d4\n",
      "\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e6d6\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: a1c1\n",
      "\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: d6e6\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: b6b7\n",
      "\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: e6d6\n",
      ". Q . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: b7b8q\n",
      "\n",
      ". Q . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: d6e7\n",
      ". . . . Q . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: b8e8\n",
      "\n",
      ". . . . Q . . .\n",
      ". . . . . . . .\n",
      ". . . . . k . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: e7f6\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . k . .\n",
      ". . . . Q . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: e8e5\n",
      "\n",
      "Result in: 66477.95ms\n",
      "OUTCOME: CHECKMATE\n",
      "Player Win: WHITE\n",
      "Number of Moves       (agent 1 WHITHE): 38\n",
      "States evaluated      (agent 1 WHITHE): 20035\n",
      "Pruning carried out   (agent 1 WHITHE): 0\n",
      "\n",
      "Number of Moves       (agent 2 BLACK): 37\n",
      "States evaluated      (agent 2 BLACK): 15004\n",
      "Pruning carried out   (agent 2 BLACK): 2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def main_chess_game():\n",
    "    game = ChessGame()\n",
    "    heuristic_a1 = HardBoardEvaluationChessGame()\n",
    "    search_algorithm_a1 = MinMaxAlphaBetaPruning(game=game, heuristic=heuristic_a1, max_depth=2)\n",
    "    search_algorithm_a2 = MinMaxAlphaBetaPruning(game=game, heuristic=heuristic_a1, max_depth=2)\n",
    "    state = StateChessGame()\n",
    "    agent1 = Agent(search_algorithm_a1, state)\n",
    "    agent2 = Agent(search_algorithm_a2, state)\n",
    "    turn_agent = 0\n",
    "    move_agent_1 = 1\n",
    "    move_agent_2 = 1\n",
    "    start_time = time.time()\n",
    "    print(\"The game of chess begins!\")\n",
    "    print(state.game_representation)\n",
    "    while not state.is_endgame():\n",
    "        if turn_agent % 2:\n",
    "            state = agent2.do_action(state)\n",
    "            move_agent_2 += 1\n",
    "            print(state.game_representation)\n",
    "            print(\"Agent 2 (BLACK) played the move:\", state.move)\n",
    "            print()\n",
    "        else:\n",
    "            state = agent1.do_action(state)\n",
    "            move_agent_1 += 1\n",
    "            print(state.game_representation)\n",
    "            print(\"Agent 1 (WHITE) played the move:\", state.move)\n",
    "            print()\n",
    "        turn_agent = turn_agent + 1\n",
    "\n",
    "        if state is None:\n",
    "            print(\"The agent was unable to resolve the issue\")\n",
    "            return\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Result in: {(end_time - start_time) * 1000:.2f}ms\")\n",
    "    print(\n",
    "        f\"OUTCOME: {state.game_representation.game_board.outcome().termination.name}\")\n",
    "    if state.game_representation.get_name_winner_player() is not None:\n",
    "        print(f\"Player Win: {state.game_representation.get_name_winner_player().upper()}\")\n",
    "    print(f\"Number of Moves       (agent 1 WHITHE): {move_agent_1}\")\n",
    "    print(f\"States evaluated      (agent 1 WHITHE): {agent1.search_algorithm.eval_count}\")\n",
    "    print(f\"Pruning carried out   (agent 1 WHITHE): {agent1.search_algorithm.prune_count}\")\n",
    "    print()\n",
    "    print(f\"Number of Moves       (agent 2 BLACK): {move_agent_2}\")\n",
    "    print(f\"States evaluated      (agent 2 BLACK): {agent2.search_algorithm.eval_count}\")\n",
    "    print(f\"Pruning carried out   (agent 2 BLACK): {agent2.search_algorithm.prune_count}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_chess_game()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:07:25.893770600Z",
     "start_time": "2023-10-29T17:06:19.405814300Z"
    }
   },
   "id": "c749630f46dcfd5f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
