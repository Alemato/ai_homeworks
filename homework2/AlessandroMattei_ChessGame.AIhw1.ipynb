{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HOMEWORK 1 - Chess Game\n",
    "**Student:** Alessandro Mattei\n",
    "\n",
    "**Matricola:** 295411\n",
    "\n",
    "**Email:** alessandro.mattei1@student.univaq.it\n",
    "\n",
    "The main components used for the implementation will be presented:\n",
    "   - Class Agent\n",
    "   - Class Game (ChessGame)\n",
    "   - Class State (StateChessGame)\n",
    "   - Heuristics (HardBoardEvaluationChessGame and SoftBoardEvaluationChessGame)\n",
    "   - Observation (ObservationBoard) \n",
    "   - Search Algorithm (MinMaxAplaBetaPruning, MinMaxAlphaBetaPruningH0Cut, MinMaxAlphaBetaPruningHlCut, MinMaxAlphaBetaPruningRegressorCut)\n",
    "   - Nonlinear Regressor\n",
    "   - CSV generator for the nonlinear regressor\n",
    "\n",
    "# Agent Class\n",
    "Represents an agent that can act based on a given search algorithm and its current view of the world."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38339eafa8cc80b5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    Represents an agent that can act based on a given search algorithm and its current view of the world.\n",
    "\n",
    "    Attributes:\n",
    "        search_algorithm: A search algorithm that the agent uses to make decisions.\n",
    "        view: The agent's current view of the world.\n",
    "        old_view: The agent's previous view of the world.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, search_algorithm, initial_state):\n",
    "        \"\"\"\n",
    "        Initializes the Agent with a search algorithm and an initial state.\n",
    "\n",
    "        :param search_algorithm: The search algorithm to be used by the agent.\n",
    "        :param initial_state: The initial state of the world as perceived by the agent.\n",
    "        \"\"\"\n",
    "        self.search_algorithm = search_algorithm\n",
    "        self.view = initial_state\n",
    "        self.old_view = None\n",
    "\n",
    "    def do_action(self, current_state_world):\n",
    "        \"\"\"\n",
    "        Updates the agent's view based on the current state of the world and the search algorithm.\n",
    "        :param current_state_world: The current state of the world.\n",
    "        :return: The updated view of the agent.\n",
    "        \"\"\"\n",
    "        self.view = self.search_algorithm.search(current_state_world)\n",
    "        self.old_view = current_state_world\n",
    "        return self.view\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.257862600Z",
     "start_time": "2023-10-29T17:06:19.205111200Z"
    }
   },
   "id": "f14441fc8c82aba7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# State\n",
    "Represents a state in a chess game, including the board configuration and various heuristic evaluations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "440b47e4f7ea4c93"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "\n",
    "class StateChessGame:\n",
    "    \"\"\"\n",
    "    Represents a state in a chess game, including the board configuration and various heuristic evaluations.\n",
    "\n",
    "    Attributes:\n",
    "        game_board (chess.Board): The current chess board configuration.\n",
    "        parent_state (StateChessGame): The parent state from which this state is derived.\n",
    "        move (chess.Move): The move that led to this state.\n",
    "        h (float): General heuristic value for the state.\n",
    "        h0 (float): Heuristic value used for h0 cutoff.\n",
    "        hl (float): Heuristic value used for hl cutoff.\n",
    "        hr (float): Heuristic value used for nonlinear regressor cutoff.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game_board=None, state_parent=None, move=None):\n",
    "        \"\"\"\n",
    "        Initializes a new game state.\n",
    "\n",
    "        :param game_board: The current chess board configuration. If None, initializes a new chess board.\n",
    "        :param state_parent: The parent state from which this state is derived.\n",
    "        :param move: The move that led to this state.\n",
    "        \"\"\"\n",
    "        self.game_board = game_board  # The current chess board (chess.Board object).\n",
    "        self.parent_state = state_parent  # The parent state from which this state is derived.\n",
    "        self.move = move  # The move that led to this state.\n",
    "        self.h = None  # General heuristic value for the state.\n",
    "        self.h0 = None  # Heuristic value used for h0 cutoff.\n",
    "        self.hl = None  # Heuristic value used for hl cutoff.\n",
    "        self.hr = None  # Heuristic value used for nonlinear regressor cutoff.\n",
    "\n",
    "        # If no game board is provided, initialize a new chess board.\n",
    "        if self.game_board is None:\n",
    "            self.game_board = chess.Board()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Checks if this state is equal to another state. States are considered equal if they have the same game\n",
    "        board configuration.\n",
    "\n",
    "        :param other: The other StateChessGame object to compare with.\n",
    "        :return: True if the states are equal, False otherwise.\n",
    "        \"\"\"\n",
    "        if not isinstance(other, StateChessGame):\n",
    "            return False\n",
    "        return self.game_board == other.game_board\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        \"\"\"\n",
    "        Checks if this state is not equal to another state. It relies on the __eq__ method.\n",
    "\n",
    "        :param other: The other StateChessGame object to compare with.\n",
    "        :return: True if the states are not equal, False otherwise.\n",
    "        \"\"\"\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Generates a hash for the state. This is based on the string representation of the game board, allowing the state\n",
    "        to be used in hash tables or sets.\n",
    "\n",
    "        :return: The hash of the state.\n",
    "        \"\"\"\n",
    "        return hash(str(self.game_board))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.334635Z",
     "start_time": "2023-10-29T17:06:19.224330500Z"
    }
   },
   "id": "a37c211095dda285"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Game Class\n",
    "Represents a chess game, providing functionalities to manage the game state and compute possible moves."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfb969b30be40656"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "from chessgame.StateChessGame import StateChessGame\n",
    "\n",
    "\n",
    "class ChessGame:\n",
    "    \"\"\"\n",
    "    Represents a chess game, providing functionalities to manage the game state and compute possible moves.\n",
    "\n",
    "    Attributes:\n",
    "        game_board (chess.Board): The current chess board configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game_board=None):\n",
    "        \"\"\"\n",
    "        Initializes a new chess game.\n",
    "\n",
    "        :param game_board: The current chess board configuration. If None, initializes a new chess board.\n",
    "        \"\"\"\n",
    "        self.game_board = game_board  # The current chess board.\n",
    "\n",
    "        # If no game board is provided, initialize a new chess board.\n",
    "        if game_board is None:\n",
    "            self.game_board = chess.Board()\n",
    "\n",
    "    def neighbors(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Generates all possible next states (neighbors) from a given state.\n",
    "\n",
    "        :param state: The current state of the chess game from which to compute neighbors.\n",
    "        :return: A list of StateChessGame objects representing possible next states.\n",
    "        \"\"\"\n",
    "        neighbors = []\n",
    "\n",
    "        # Iterate through all legal moves from the current state.\n",
    "        for legal_move in state.game_board.legal_moves:\n",
    "            # Copy the current game board and make the legal move.\n",
    "            new_game_board = state.game_board.copy()\n",
    "            new_game_board.push(legal_move)\n",
    "\n",
    "            # Create a new StateChessGame object for the resulting game state.\n",
    "            neighbor = StateChessGame(game_board=new_game_board, state_parent=state, move=legal_move)\n",
    "            neighbors.append(neighbor)\n",
    "        return neighbors\n",
    "\n",
    "    def get_name_winner_player(self, game_board):\n",
    "        \"\"\"\n",
    "        Determines the name of the winning player if the game is in checkmate.\n",
    "\n",
    "        :param game_board: The chess board to check for checkmate and winner.\n",
    "        :return: The name of the winning player (\"White\" or \"Black\") if there's a checkmate, otherwise None.\n",
    "        \"\"\"\n",
    "        # Check if the current game state is a checkmate.\n",
    "        if game_board.is_checkmate():\n",
    "            # Get the outcome of the game.\n",
    "            outcome = game_board.outcome()\n",
    "            if outcome is not None:\n",
    "                # Return \"White\" or \"Black\" depending on the winner.\n",
    "                return \"White\" if outcome.winner else \"Black\"\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.334635Z",
     "start_time": "2023-10-29T17:06:19.326060400Z"
    }
   },
   "id": "64e3290e0dcd39b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Heuristics\n",
    "## Single Evaluations\n",
    "### Constants"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bac4e63a1657e95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "PIECE_VALUE = {\n",
    "    chess.PAWN: 1,\n",
    "    chess.KNIGHT: 3,\n",
    "    chess.BISHOP: 3,\n",
    "    chess.ROOK: 5,\n",
    "    chess.QUEEN: 9,\n",
    "    chess.KING: 0  # Il valore del re è gestito separatamente\n",
    "}\n",
    "\n",
    "# Tabelle di posizione per il pedone\n",
    "PAWN_TABLE = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    5, 10, 10, -20, -20, 10, 10, 5,\n",
    "    5, -5, -10, 0, 0, -10, -5, 5,\n",
    "    0, 0, 0, 20, 20, 0, 0, 0,\n",
    "    5, 5, 10, 25, 25, 10, 5, 5,\n",
    "    10, 10, 20, 30, 30, 20, 10, 10,\n",
    "    50, 50, 50, 50, 50, 50, 50, 50,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per il cavallo\n",
    "KNIGHT_TABLE = [\n",
    "    -50, -40, -30, -30, -30, -30, -40, -50,\n",
    "    -40, -20, 0, 5, 5, 0, -20, -40,\n",
    "    -30, 5, 10, 15, 15, 10, 5, -30,\n",
    "    -30, 0, 15, 20, 20, 15, 0, -30,\n",
    "    -30, 5, 15, 20, 20, 15, 5, -30,\n",
    "    -30, 0, 10, 15, 15, 10, 0, -30,\n",
    "    -40, -20, 0, 0, 0, 0, -20, -40,\n",
    "    -50, -40, -30, -30, -30, -30, -40, -50,\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per l'alfiere\n",
    "BISHOP_TABLE = [\n",
    "    -20, -10, -10, -10, -10, -10, -10, -20,\n",
    "    -10, 5, 0, 0, 0, 0, 5, -10,\n",
    "    -10, 10, 10, 10, 10, 10, 10, -10,\n",
    "    -10, 0, 10, 10, 10, 10, 0, -10,\n",
    "    -10, 5, 5, 10, 10, 5, 5, -10,\n",
    "    -10, 0, 5, 10, 10, 5, 0, -10,\n",
    "    -10, 0, 0, 0, 0, 0, 0, -10,\n",
    "    -20, -10, -10, -10, -10, -10, -10, -20\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per la torre\n",
    "ROOK_TABLE = [\n",
    "    0, 0, 0, 5, 5, 0, 0, 0,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    5, 10, 10, 10, 10, 10, 10, 5,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per la regina\n",
    "QUEEEN_TABLE = [\n",
    "    -20, -10, -10, -5, -5, -10, -10, -20,\n",
    "    -10, 0, 5, 0, 0, 0, 0, -10,\n",
    "    -10, 5, 5, 5, 5, 5, 0, -10,\n",
    "    0, 0, 5, 5, 5, 5, 0, -5,\n",
    "    -5, 0, 5, 5, 5, 5, 0, -5,\n",
    "    -10, 0, 5, 5, 5, 5, 0, -10,\n",
    "    -10, 0, 0, 0, 0, 0, 0, -10,\n",
    "    -20, -10, -10, -5, -5, -10, -10, -20\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per il re (inizio gioco)\n",
    "KING_INITGAME_TABLE = [\n",
    "    20, 30, 10, 0, 0, 10, 30, 20,\n",
    "    20, 20, 0, 0, 0, 0, 20, 20,\n",
    "    -10, -20, -20, -20, -20, -20, -20, -10,\n",
    "    -20, -30, -30, -40, -40, -30, -30, -20,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30\n",
    "]\n",
    "\n",
    "# Tabelle di posizione per il re (fine gioco)\n",
    "KING_ENDGAME_TABLE = [\n",
    "    -50, -40, -30, -20, -20, -30, -40, -50,\n",
    "    -30, -20, -10, 0, 0, -10, -20, -30,\n",
    "    -30, -10, 20, 30, 30, 20, -10, -30,\n",
    "    -30, -10, 30, 40, 40, 30, -10, -30,\n",
    "    -30, -10, 30, 40, 40, 30, -10, -30,\n",
    "    -30, -10, 20, 30, 30, 20, -10, -30,\n",
    "    -30, -30, 0, 0, 0, 0, -30, -30,\n",
    "    -50, -30, -30, -30, -30, -30, -30, -50\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55eaa0e7baa6d5b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate Board Without King\n",
    "\n",
    "Provides heuristic evaluation of a chess board state, focusing on piece values and game conditions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6eb53a65cfd2a44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluateBoardWithoutKing:\n",
    "    \"\"\"\n",
    "    Provides heuristic evaluation of a chess board state, focusing on piece values and game conditions.\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): Flag to indicate whether to evaluate endgame phases differently.\n",
    "        normalize_result (bool): Flag to indicate whether to normalize the evaluation result.\n",
    "        h_max_value (int): Maximum heuristic value for normalization.\n",
    "        h_min_value (int): Minimum heuristic value for normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation and result normalization.\n",
    "\n",
    "        :param evaluate_end_game_phase: Set to True to evaluate endgame phases differently.\n",
    "        :param normalize_result: Set to True to normalize the evaluation result.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase  # Flag to evaluate endgame phases.\n",
    "        self.normalize_result = normalize_result  # Flag to normalize the evaluation result.\n",
    "        self.h_max_value = 99  # Maximum heuristic value for normalization.\n",
    "        self.h_min_value = -99  # Minimum heuristic value for normalization.\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the heuristic of a given game state.\n",
    "\n",
    "        :param state: StateChessGame object representing the current state of the chess game.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        # Evaluates endgame phase or normalizes the result based on the flags set in the constructor.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        Similar to h() but operates directly on a chess board and allows specifying normalization bounds.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Evaluates the endgame phase, normalizes the result, or provides raw evaluation.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Private method for raw heuristic evaluation of a board.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The raw heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "\n",
    "        # If the game is over, returns high positive or negative values for checkmate, and zero for other endings.\n",
    "        if board.is_game_over():\n",
    "            if board.is_checkmate():\n",
    "                return -99 if board.turn else 99\n",
    "            else:\n",
    "                return 0  # Handles stalemate and insufficient material.\n",
    "\n",
    "        # Piece-based evaluation, optimized.\n",
    "        eval = sum(PIECE_VALUE[piece] * (len(board.pieces(piece, chess.WHITE)) - len(board.pieces(piece, chess.BLACK)))\n",
    "                   for piece in PIECE_VALUE)\n",
    "        # Slightly favors the player whose turn it is, as they might have the initiative.\n",
    "        eval += 0.1 if board.turn else -0.1\n",
    "\n",
    "        return eval\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb9bf11e1fcfcec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Central Control Score\n",
    "\n",
    "Provides heuristic evaluation of a chess board state with a focus on the control of central squares."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d9340a75c59409c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EvaluateCentralControlScore:\n",
    "    \"\"\"\n",
    "    Provides heuristic evaluation of a chess board state with a focus on the control of central squares.\n",
    "\n",
    "    Attributes:\n",
    "        evaluate_end_game_phase (bool): Flag to indicate whether to evaluate endgame phases differently.\n",
    "        normalize_result (bool): Flag to indicate whether to normalize the evaluation result.\n",
    "        h_max_value (float): Maximum heuristic value for normalization.\n",
    "        h_min_value (float): Minimum heuristic value for normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evaluate_end_game_phase=False, normalize_result=False):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator with options for endgame evaluation and result normalization.\n",
    "\n",
    "        :param evaluate_end_game_phase: Set to True to evaluate endgame phases differently.\n",
    "        :param normalize_result: Set to True to normalize the evaluation result.\n",
    "        \"\"\"\n",
    "        self.evaluate_end_game_phase = evaluate_end_game_phase  # Flag to evaluate endgame phases.\n",
    "        self.normalize_result = normalize_result  # Flag to normalize the evaluation result.\n",
    "        self.h_max_value = 1.2  # Maximum heuristic value for normalization.\n",
    "        self.h_min_value = -1.2  # Minimum heuristic value for normalization.\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the heuristic of a given game state.\n",
    "\n",
    "        :param state: StateChessGame object representing the current state of the chess game.\n",
    "        :return: The heuristic value of the state.\n",
    "        \"\"\"\n",
    "        # Evaluates endgame phase or normalizes the result based on the constructor's flags.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(state.game_board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(state.game_board)\n",
    "            return self.__normalize(raw_eval)\n",
    "        else:\n",
    "            return self.__h(state.game_board)\n",
    "\n",
    "    def h_piccolo(self, board):\n",
    "        \"\"\"\n",
    "        Similar to h() but operates directly on a chess board and allows specifying normalization bounds.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Evaluates the endgame phase, normalizes the result, or provides raw evaluation.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            return self.__h(board)\n",
    "        elif self.normalize_result:\n",
    "            raw_eval = self.__h(board)\n",
    "            return self.__normalize(raw_eval, 10, -10)\n",
    "        else:\n",
    "            return self.__h(board)\n",
    "\n",
    "    def __h(self, board):\n",
    "        \"\"\"\n",
    "        Private method for raw heuristic evaluation of a board.\n",
    "\n",
    "        :param board: The chess board to evaluate.\n",
    "        :return: The raw heuristic value of the board.\n",
    "        \"\"\"\n",
    "        # Special handling for endgame phase.\n",
    "        if self.evaluate_end_game_phase:\n",
    "            game_over_eval = None\n",
    "            # Assign extreme values for checkmate situations.\n",
    "            if board.is_checkmate():\n",
    "                outcome = board.outcome()\n",
    "                if outcome is not None:\n",
    "                    game_over_eval = float(\"inf\") if outcome.winner else float(\"-inf\")\n",
    "            # Assign zero for draw situations.\n",
    "            if board.is_stalemate() or board.is_insufficient_material() or board.is_seventyfive_moves() or board.is_fivefold_repetition():\n",
    "                game_over_eval = 0\n",
    "\n",
    "            if game_over_eval is not None:\n",
    "                return game_over_eval\n",
    "\n",
    "        # Assign points for control of each central square.\n",
    "        center_squares = [chess.D4, chess.E4, chess.D5, chess.E5]\n",
    "        score = 0\n",
    "        central_square_control = 0.3  # Value to calibrate based on your specific heuristic.\n",
    "\n",
    "        # Check if central squares are controlled by White or Black.\n",
    "        for square in center_squares:\n",
    "            if board.is_attacked_by(chess.WHITE, square):\n",
    "                score += central_square_control\n",
    "            if board.is_attacked_by(chess.BLACK, square):\n",
    "                score -= central_square_control\n",
    "\n",
    "        # Adjust the score for the current player.\n",
    "        return score if board.turn == chess.WHITE else -score\n",
    "\n",
    "    def __normalize(self, value, maxv=100, minv=-100):\n",
    "        \"\"\"\n",
    "        Normalizes the evaluation value within a specified range.\n",
    "\n",
    "        :param value: The value to be normalized.\n",
    "        :param maxv: The maximum value for normalization. Defaults to 100.\n",
    "        :param minv: The minimum value for normalization. Defaults to -100.\n",
    "        :return: The normalized value.\n",
    "        \"\"\"\n",
    "        # Normalizes the value within the range from minv to maxv.\n",
    "        if value >= 0:\n",
    "            # Normalizes positive values.\n",
    "            normalized = (value / self.h_max_value) * 100\n",
    "        else:\n",
    "            # Normalizes negative values.\n",
    "            normalized = (value / abs(self.h_min_value)) * 100\n",
    "\n",
    "        # Limits the normalized value between minv and maxv.\n",
    "        normalized = max(min(normalized, maxv), minv)\n",
    "        return normalized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e1f0f1247ff5eed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "541b865006da4f6c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SoftBoardEvaluationChessGame\n",
    "Provides an evaluation of a chess board based on various criteria, helping to determine the quality of a board state for use in search algorithms.\n",
    "This heuristic is the simplest implemented.\n",
    "Combine various heuristics by summing the value of them.\n",
    "\n",
    "Combined heuristics:\n",
    "   - evaluate_board: Evaluates the overall quality of the board.\n",
    "   - material_evaluation: Evaluates the board based on the material present.\n",
    "   - piece_square_evaluation: Evaluates the board based on piece positions.\n",
    "   - mobility_evaluation: Evaluates the board based on piece mobility.\n",
    "   - king_safety_evaluation: Evaluates the board based on king safety.\n",
    "   - center_control_evaluation: Evaluates board control of center squares."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c6418cf4ad2348f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "PIECE_VALUES = {\n",
    "    chess.PAWN: 1,\n",
    "    chess.KNIGHT: 3,\n",
    "    chess.BISHOP: 3,\n",
    "    chess.ROOK: 5,\n",
    "    chess.QUEEN: 9,\n",
    "    chess.KING: 0  # Il re ha un valore speciale\n",
    "}\n",
    "\n",
    "# Tabelle di pezzi\n",
    "PAWN_TABLE = [\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [5, 10, 10, -20, -20, 10, 10, 5],\n",
    "    [5, -5, -10, 0, 0, -10, -5, 5],\n",
    "    [0, 0, 0, 20, 20, 0, 0, 0],\n",
    "    [5, 5, 10, 25, 25, 10, 5, 5],\n",
    "    [10, 10, 20, 30, 30, 20, 10, 10],\n",
    "    [50, 50, 50, 50, 50, 50, 50, 50],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "KNIGHT_TABLE = [\n",
    "    [-50, -40, -30, -30, -30, -30, -40, -50],\n",
    "    [-40, -20, 0, 5, 5, 0, -20, -40],\n",
    "    [-30, 5, 10, 15, 15, 10, 5, -30],\n",
    "    [-30, 0, 15, 20, 20, 15, 0, -30],\n",
    "    [-30, 5, 15, 20, 20, 15, 5, -30],\n",
    "    [-30, 0, 10, 15, 15, 10, 0, -30],\n",
    "    [-40, -20, 0, 0, 0, 0, -20, -40],\n",
    "    [-50, -40, -30, -30, -30, -30, -40, -50]\n",
    "]\n",
    "\n",
    "BISHOP_TABLE = [\n",
    "    [-20, -10, -10, -10, -10, -10, -10, -20],\n",
    "    [-10, 5, 0, 0, 0, 0, 5, -10],\n",
    "    [-10, 10, 10, 10, 10, 10, 10, -10],\n",
    "    [-10, 0, 10, 10, 10, 10, 0, -10],\n",
    "    [-10, 5, 5, 10, 10, 5, 5, -10],\n",
    "    [-10, 0, 5, 10, 10, 5, 0, -10],\n",
    "    [-10, 0, 0, 0, 0, 0, 0, -10],\n",
    "    [-20, -10, -10, -10, -10, -10, -10, -20]\n",
    "]\n",
    "\n",
    "ROOK_TABLE = [\n",
    "    [0, 0, 0, 5, 5, 0, 0, 0],\n",
    "    [-5, 0, 0, 0, 0, 0, 0, -5],\n",
    "    [-5, 0, 0, 0, 0, 0, 0, -5],\n",
    "    [-5, 0, 0, 0, 0, 0, 0, -5],\n",
    "    [-5, 0, 0, 0, 0, 0, 0, -5],\n",
    "    [-5, 0, 0, 0, 0, 0, 0, -5],\n",
    "    [5, 10, 10, 10, 10, 10, 10, 5],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "QUEEN_TABLE = [\n",
    "    [-20, -10, -10, -5, -5, -10, -10, -20],\n",
    "    [-10, 0, 0, 0, 0, 0, 0, -10],\n",
    "    [-10, 0, 5, 5, 5, 5, 0, -10],\n",
    "    [-5, 0, 5, 5, 5, 5, 0, -5],\n",
    "    [0, 0, 5, 5, 5, 5, 0, -5],\n",
    "    [-10, 5, 5, 5, 5, 5, 0, -10],\n",
    "    [-10, 0, 5, 0, 0, 0, 0, -10],\n",
    "    [-20, -10, -10, -5, -5, -10, -10, -20]\n",
    "]\n",
    "\n",
    "KING_TABLE = [\n",
    "    [20, 30, 10, 0, 0, 10, 30, 20],\n",
    "    [20, 20, 0, 0, 0, 0, 20, 20],\n",
    "    [-10, -20, -20, -20, -20, -20, -20, -10],\n",
    "    [-20, -30, -30, -40, -40, -30, -30, -20],\n",
    "    [-30, -40, -40, -50, -50, -40, -40, -30],\n",
    "    [-30, -40, -40, -50, -50, -40, -40, -30],\n",
    "    [-30, -40, -40, -50, -50, -40, -40, -30],\n",
    "    [-30, -40, -40, -50, -50, -40, -40, -30]\n",
    "]\n",
    "\n",
    "# Pesi, Penalità e bonus\n",
    "OPEN_FILE_PENALTY = -25\n",
    "ADJACENT_PAWN_BONUS = 10\n",
    "KING_SAFETY_WEIGHT = 0.5\n",
    "MOBILITY_WEIGHT = 0.1\n",
    "CENTER_CONTROL_WEIGHT = 0.5\n",
    "CENTER_SQUARES = [chess.D4, chess.D5, chess.E4, chess.E5]\n",
    "\n",
    "\n",
    "class SoftBoardEvaluationChessGame:\n",
    "    \"\"\"\n",
    "    Provides an evaluation of a chess board based on various criteria, helping\n",
    "    to determine the quality of a board state for use in search algorithms.\n",
    "\n",
    "    Methods:\n",
    "        evaluate_board: Evaluates the overall quality of the board.\n",
    "        material_evaluation: Evaluates the board based on the material present.\n",
    "        piece_square_evaluation: Evaluates the board based on piece positions.\n",
    "        mobility_evaluation: Evaluates the board based on piece mobility.\n",
    "        king_safety_evaluation: Evaluates the board based on king safety.\n",
    "        center_control_evaluation: Evaluates board control of center squares.\n",
    "    \"\"\"\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the overall quality of the board based on various criteria.\n",
    "        :param state:The current state of the chess game.\n",
    "        :return: The evaluation score of the board.\n",
    "        \"\"\"\n",
    "        board = state.game_representation.game_board\n",
    "        h1 = state.game_over_eval()\n",
    "        if h1 is not None:\n",
    "            return h1\n",
    "        else:\n",
    "            total_evaluation = (\n",
    "                    self.piece_material_evaluation(board) +\n",
    "                    self.piece_position_evaluation(board) +\n",
    "                    self.mobility_evaluation(board) +\n",
    "                    self.king_safety_evaluation(board) +\n",
    "                    self.center_control_evaluation(board)\n",
    "            )\n",
    "            return total_evaluation\n",
    "\n",
    "    def piece_material_evaluation(self, board):\n",
    "        \"\"\"\n",
    "        Evaluates the board based on the material (pieces) present.\n",
    "\n",
    "        This function calculates a numerical evaluation score for a given chess board based on the material (pieces)\n",
    "        present on the board. It assigns scores to pieces based on their type and color, and the final score reflects\n",
    "        the material advantage or disadvantage of one side over the other.\n",
    "\n",
    "        :param board: The current chess board (chess.Board object). :return: The evaluation score based on material.\n",
    "        A positive score indicates an advantage for white, while a negative score indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        evaluation = 0.0\n",
    "        # Iterate through all squares on the chess board and evaluate the material present on each square.\n",
    "        for square, piece in board.piece_map().items():\n",
    "            # Get the value of the chess piece based on its type (pawn, knight, bishop, rook, queen, king).\n",
    "            piece_value = PIECE_VALUES[piece.piece_type]\n",
    "\n",
    "            # Check if the piece is white (color is chess.WHITE) or black (color is chess.BLACK) and adjust the\n",
    "            # evaluation score accordingly.\n",
    "            if piece.color == chess.WHITE:\n",
    "                evaluation += piece_value  # Add the piece value for white.\n",
    "            else:\n",
    "                evaluation -= piece_value  # Subtract the piece value for black.\n",
    "        return evaluation\n",
    "\n",
    "    def piece_position_evaluation(self, board):\n",
    "        \"\"\"\n",
    "        Evaluates the board based on the positions of the pieces.\n",
    "\n",
    "        This function calculates a numerical evaluation score for a given chess board based on the positions of the\n",
    "        pieces. It assigns scores to pieces based on their positions using predefined tables.\n",
    "\n",
    "        :param board: The current chess board (chess.Board object). :return: The evaluation score based on piece\n",
    "        positions. A positive score indicates an advantage for white based on piece positions, while a negative score\n",
    "        indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        evaluation = 0.0\n",
    "\n",
    "        for square, piece in board.piece_map().items():\n",
    "            # Determine which piece type (pawn, knight, bishop, rook, queen, king) is on the current square.\n",
    "            if piece.piece_type == chess.PAWN:\n",
    "                table = PAWN_TABLE\n",
    "            elif piece.piece_type == chess.KNIGHT:\n",
    "                table = KNIGHT_TABLE\n",
    "            elif piece.piece_type == chess.BISHOP:\n",
    "                table = BISHOP_TABLE\n",
    "            elif piece.piece_type == chess.ROOK:\n",
    "                table = ROOK_TABLE\n",
    "            elif piece.piece_type == chess.QUEEN:\n",
    "                table = QUEEN_TABLE\n",
    "            elif piece.piece_type == chess.KING:\n",
    "                table = KING_TABLE\n",
    "\n",
    "            # Calculate the row and column of the square.\n",
    "            row = square // 8\n",
    "            col = square % 8\n",
    "\n",
    "            # Check if the piece is white (color is chess.WHITE) or black (color is chess.BLACK) and adjust the\n",
    "            # evaluation score accordingly.\n",
    "            if piece.color == chess.WHITE:\n",
    "                evaluation += table[row][col]  # Add the piece value for white.\n",
    "            else:\n",
    "                # Tables are made for white, so let's reverse for black\n",
    "                evaluation -= table[7 - row][col]  # Subtract the piece value for black.\n",
    "\n",
    "        return evaluation\n",
    "\n",
    "    def mobility_evaluation(self, board):\n",
    "        \"\"\"\n",
    "        Evaluates the board based on the mobility (legal moves) of the pieces. This function calculates a numerical\n",
    "        evaluation score for a given chess board based on the mobility of the pieces.\n",
    "        Mobility refers to the number of legal moves that can be made by each side (white and black) on the board.\n",
    "\n",
    "        :param board: The current chess board (chess.Board object).\n",
    "        :return: The evaluation score based on mobility. A positive score indicates an advantage for the side with more\n",
    "                 mobility, while a negative score indicates an advantage for the side with less mobility.\n",
    "        \"\"\"\n",
    "        evaluation = 0.0\n",
    "\n",
    "        # Calculate mobility for white and black\n",
    "        white_mobility = len(list(board.legal_moves))\n",
    "        board.push(chess.Move.null())  # Perform a null move to change the turn\n",
    "        black_mobility = len(list(board.legal_moves))\n",
    "        board.pop()  # Go back to the original shift\n",
    "        # Evaluate mobility based on weights\n",
    "        evaluation += MOBILITY_WEIGHT * (white_mobility - black_mobility)\n",
    "\n",
    "        return evaluation\n",
    "\n",
    "    def king_safety_evaluation(self, board):\n",
    "        \"\"\"\n",
    "        Evaluates the safety of kings on the board.\n",
    "\n",
    "        This function calculates a numerical evaluation score for a given chess board based on the safety of both kings.\n",
    "        It considers factors such as pawn protection and open files near the kings.\n",
    "\n",
    "        :param board: The current chess board (chess.Board object).\n",
    "        :return: The evaluation score based on king safety. A positive score indicates a safer position for the white\n",
    "                 king, while a negative score indicates a safer position for the black king.\n",
    "        \"\"\"\n",
    "        evaluation = 0.0\n",
    "\n",
    "        # Find the positions of the white and black kings on the board\n",
    "        white_king_square = list(board.pieces(chess.KING, chess.WHITE))[0]\n",
    "        black_king_square = list(board.pieces(chess.KING, chess.BLACK))[0]\n",
    "\n",
    "        # Evaluate the safety of the white king\n",
    "        if board.attacks(white_king_square) & board.pieces(chess.PAWN, chess.BLACK):\n",
    "            # If black pawns can attack the white king, penalize the evaluation (open file penalty).\n",
    "            evaluation += OPEN_FILE_PENALTY\n",
    "        # Check adjacent squares to the white king for friendly pawns and provide a bonus for pawn protection.\n",
    "        for square in chess.SQUARES:\n",
    "            if abs(square - white_king_square) in [1, 7, 8, 9] and board.piece_at(\n",
    "                    square) == chess.PAWN and board.color_at(square) == chess.WHITE:\n",
    "                evaluation += ADJACENT_PAWN_BONUS\n",
    "\n",
    "        # Evaluate the safety of the black king\n",
    "        if board.attacks(black_king_square) & board.pieces(chess.PAWN, chess.WHITE):\n",
    "            # If white pawns can attack the black king, penalize the evaluation (open file penalty).\n",
    "            evaluation -= OPEN_FILE_PENALTY\n",
    "        # Check adjacent squares to the black king for friendly pawns and provide a bonus for pawn protection.\n",
    "        for square in chess.SQUARES:\n",
    "            if abs(square - black_king_square) in [1, 7, 8, 9] and board.piece_at(\n",
    "                    square) == chess.PAWN and board.color_at(square) == chess.BLACK:\n",
    "                evaluation -= ADJACENT_PAWN_BONUS\n",
    "\n",
    "        return evaluation * KING_SAFETY_WEIGHT\n",
    "\n",
    "    def center_control_evaluation(self, board):\n",
    "        \"\"\"\n",
    "        Evaluates control of the center of the chessboard.\n",
    "\n",
    "        This function calculates a numerical evaluation score for a given chess board based on control of the central squares\n",
    "        of the board. It assigns scores to pieces occupying central squares and gives additional scores for pieces\n",
    "        controlling central squares.\n",
    "\n",
    "        :param board: The current chess board (chess.Board object).\n",
    "        :return: The evaluation score based on control of the center. A positive score indicates better control of the center\n",
    "                 by white, while a negative score indicates better control by black.\n",
    "        \"\"\"\n",
    "\n",
    "        evaluation = 0.0\n",
    "\n",
    "        for square in CENTER_SQUARES:\n",
    "            # If a central square is occupied by a piece, assign a score based on the piece color.\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                if piece.color == chess.WHITE:\n",
    "                    evaluation += 1\n",
    "                else:\n",
    "                    evaluation -= 1\n",
    "\n",
    "            # Assign additional scores based on the number of attackers to central squares by each side.\n",
    "            attackers = board.attackers(chess.WHITE, square)\n",
    "            evaluation += len(attackers)\n",
    "            attackers = board.attackers(chess.BLACK, square)\n",
    "            evaluation -= len(attackers)\n",
    "\n",
    "        return evaluation * CENTER_CONTROL_WEIGHT\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.356949100Z",
     "start_time": "2023-10-29T17:06:19.330626700Z"
    }
   },
   "id": "f80d042f3ea3d618"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HardBoardEvaluationChessGame\n",
    "Provides an evaluation of a chess board based on various criteria, helping to determine the quality of a board state for use in search algorithms.\n",
    "This heuristic is the most complex implemented.\n",
    "Combine various heuristics by summing the value of them.\n",
    "\n",
    "Combined heuristics:\n",
    "   - king_safety: Evaluates the board based on king safety.\n",
    "   - all_piece_values_and_piece_square_tables: Evaluates the overall quality of the board.\n",
    "   - center_control: Evaluate control of the central squares on the chessboard.\n",
    "   - mobility: Evaluate the mobility of pieces on the chessboard.\n",
    "   - attack_value: Evaluate the value of piece attacks on the chessboard.\n",
    "   - rooks_on_open_files: Evaluate the presence of rooks on open files in the chessboard.\n",
    "   - check_forks: Evaluate the presence of fork opportunities in the chess position.\n",
    "   - check_pins: Evaluate the presence of pinned pieces in the chess position."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20220039b0f5673c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Dictionary defining the intrinsic values for each chess piece.\n",
    "piece_values = {\n",
    "    \"p\": 100,  # Value of a Pawn\n",
    "    \"n\": 320,  # Value of a Knight\n",
    "    \"b\": 330,  # Value of a Bishop\n",
    "    \"r\": 500,  # Value of a Rook\n",
    "    \"q\": 900,  # Value of a Queen\n",
    "    \"k\": 20000,  # Value of a King (set very high to represent its critical importance)\n",
    "}\n",
    "\n",
    "# Piece-square table for the white pawn, defining values based on pawn's position on the board.\n",
    "pawn_white_table = [\n",
    "    0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    5, 10, 10, -20, -20, 10, 10, 5,\n",
    "    5, -5, -10, 0, 0, -10, -5, 5,\n",
    "    0, 0, 0, 20, 20, 0, 0, 0,\n",
    "    5, 5, 10, 25, 25, 10, 5, 5,\n",
    "    10, 10, 20, 30, 30, 20, 10, 10,\n",
    "    50, 50, 50, 50, 50, 50, 50, 50,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0\n",
    "]\n",
    "\n",
    "# The black pawn's piece-square table is just a reversed version of the white pawn's table.\n",
    "pawn_black_table = list(reversed(pawn_white_table))\n",
    "\n",
    "# Piece-square table for the white knight.\n",
    "knight_white_table = [\n",
    "    -50, -40, -30, -30, -30, -30, -40, -50,\n",
    "    -40, -20, 0, 5, 5, 0, -20, -40,\n",
    "    -30, 5, 10, 15, 15, 10, 5, -30,\n",
    "    -30, 0, 15, 20, 20, 15, 0, -30,\n",
    "    -30, 5, 15, 20, 20, 15, 5, -30,\n",
    "    -30, 0, 10, 15, 15, 10, 0, -30,\n",
    "    -40, -20, 0, 0, 0, 0, -20, -40,\n",
    "    -50, -40, -30, -30, -30, -30, -40, -50\n",
    "]\n",
    "\n",
    "# The black knight's table is a reversed version of the white knight's table.\n",
    "knight_black_table = list(reversed(knight_white_table))\n",
    "\n",
    "# Piece-square table for the white bishop.\n",
    "bishop_white_table = [\n",
    "    -20, -10, -10, -10, -10, -10, -10, -20,\n",
    "    -10, 5, 0, 0, 0, 0, 5, -10,\n",
    "    -10, 10, 10, 10, 10, 10, 10, -10,\n",
    "    -10, 0, 10, 10, 10, 10, 0, -10,\n",
    "    -10, 5, 5, 10, 10, 5, 5, -10,\n",
    "    -10, 0, 5, 10, 10, 5, 0, -10,\n",
    "    -10, 0, 0, 0, 0, 0, 0, -10,\n",
    "    -20, -10, -10, -10, -10, -10, -10, -20\n",
    "]\n",
    "\n",
    "# The black bishop's table is a reversed version of the white bishop's table.\n",
    "bishop_black_table = list(reversed(bishop_white_table))\n",
    "\n",
    "# Piece-square table for the white rook.\n",
    "rook_white_table = [\n",
    "    0, 0, 0, 5, 5, 0, 0, 0,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    -5, 0, 0, 0, 0, 0, 0, -5,\n",
    "    5, 10, 10, 10, 10, 10, 10, 5,\n",
    "    0, 0, 0, 0, 0, 0, 0, 0\n",
    "]\n",
    "\n",
    "# The black rook's table is a reversed version of the white rook's table.\n",
    "rook_black_table = list(reversed(rook_white_table))\n",
    "\n",
    "# Piece-square table for the white queen.\n",
    "queen_white_table = [\n",
    "    -20, -10, -10, -5, -5, -10, -10, -20,\n",
    "    -10, 0, 0, 0, 0, 0, 0, -10,\n",
    "    -10, 5, 5, 5, 5, 5, 0, -10,\n",
    "    0, 0, 5, 5, 5, 5, 0, -5,\n",
    "    -5, 0, 5, 5, 5, 5, 0, -5,\n",
    "    -10, 0, 5, 5, 5, 5, 0, -10,\n",
    "    -10, 0, 0, 0, 0, 0, 0, -10,\n",
    "    -20, -10, -10, -5, -5, -10, -10, -20\n",
    "]\n",
    "\n",
    "# The black queen's table is a reversed version of the white queen's table.\n",
    "queen_black_table = list(reversed(queen_white_table))\n",
    "\n",
    "# Piece-square table for the white king during the middle game.\n",
    "king_white_table = [\n",
    "    20, 30, 10, 0, 0, 10, 30, 20,\n",
    "    20, 20, 0, 0, 0, 0, 20, 20,\n",
    "    -10, -20, -20, -20, -20, -20, -20, -10,\n",
    "    -20, -30, -30, -40, -40, -30, -30, -20,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30,\n",
    "    -30, -40, -40, -50, -50, -40, -40, -30\n",
    "]\n",
    "\n",
    "# The black king's table is a reversed version of the white king's table.\n",
    "king_black_table = list(reversed(king_white_table))\n",
    "\n",
    "# Piece-square table for the white king during the endgame.\n",
    "king_white_table_endgame = [\n",
    "    -50, -30, -30, -30, -30, -30, -30, -50,\n",
    "    -30, -30, 0, 0, 0, 0, -30, -30,\n",
    "    -30, -10, 20, 30, 30, 20, -10, -30,\n",
    "    -30, -10, 30, 40, 40, 30, -10, -30,\n",
    "    -30, -10, 30, 40, 40, 30, -10, -30,\n",
    "    -30, -10, 20, 30, 30, 20, -10, -30,\n",
    "    -30, -20, -10, 0, 0, -10, -20, -30,\n",
    "    -50, -40, -30, -20, -20, -30, -40, -50\n",
    "]\n",
    "\n",
    "# The black king's endgame table is a reversed version of the white king's endgame table.\n",
    "king_black_table_endgame = list(reversed(king_white_table_endgame))\n",
    "\n",
    "# A comprehensive dictionary containing piece-square tables for each piece and color.\n",
    "# The tables indicate the value of placing a piece on a specific square.\n",
    "piece_square_tables = {\n",
    "    \"p\": pawn_black_table,  # Black pawn\n",
    "    \"n\": knight_black_table,  # Black knight\n",
    "    \"b\": bishop_black_table,  # Black bishop\n",
    "    \"r\": rook_black_table,  # Black rook\n",
    "    \"q\": queen_black_table,  # Black queen\n",
    "    \"k\": {\"early\": king_black_table, \"end\": king_black_table_endgame},  # Black king (both middle game and endgame)\n",
    "\n",
    "    \"P\": pawn_white_table,  # White pawn\n",
    "    \"N\": knight_white_table,  # White knight\n",
    "    \"B\": bishop_white_table,  # White bishop\n",
    "    \"R\": rook_white_table,  # White rook\n",
    "    \"Q\": queen_white_table,  # White queen\n",
    "    \"K\": {\"early\": king_white_table, \"end\": king_white_table_endgame},  # White king (both middle game and endgame)\n",
    "}\n",
    "\n",
    "\n",
    "class HardBoardEvaluationChessGame:\n",
    "    \"\"\"\n",
    "    Provides an evaluation of a chess board based on various criteria, helping\n",
    "    to determine the quality of a board state for use in search algorithms.\n",
    "\n",
    "    Methods:\n",
    "        king_safety: Evaluates the board based on king safety.\n",
    "        all_piece_values_and_piece_square_tables: Evaluates the overall quality of the board.\n",
    "        center_control: Evaluate control of the central squares on the chessboard.\n",
    "        mobility: Evaluate the mobility of pieces on the chessboard.\n",
    "        attack_value: Evaluate the value of piece attacks on the chessboard.\n",
    "        rooks_on_open_files: Evaluate the presence of rooks on open files in the chessboard.\n",
    "        check_forks: Evaluate the presence of fork opportunities in the chess position.\n",
    "        check_pins: Evaluate the presence of pinned pieces in the chess position.\n",
    "    \"\"\"\n",
    "\n",
    "    def h(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates the overall quality of the board based on various criteria.\n",
    "        :param state:The current state of the chess game.\n",
    "        :return: The evaluation score of the board.\n",
    "        \"\"\"\n",
    "        h1 = state.game_over_eval()\n",
    "        if h1 is not None:\n",
    "            return h1\n",
    "        else:\n",
    "            return (\n",
    "                    self.king_safety(state) +\n",
    "                    self.all_piece_values_and_piece_square_tables(state) +\n",
    "                    self.center_control(state) +\n",
    "                    self.mobility(state) +\n",
    "                    self.attack_value(state) +\n",
    "                    self.rooks_on_open_files(state) +\n",
    "                    self.check_forks(state) +\n",
    "                    self.check_pins(state)\n",
    "            )\n",
    "\n",
    "    def king_safety(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluates king safety for both sides.\n",
    "\n",
    "        This function calculates the king safety evaluation based on the positions of kings and rooks. It penalizes the\n",
    "        side if its king is on an open file with an opposing rook.\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object).\n",
    "        :return: The evaluation score for king safety. Positive score indicates safer kings for white, and negative score\n",
    "                 indicates safer kings for black.\n",
    "        \"\"\"\n",
    "        board = state.game_representation.game_board\n",
    "        value = 0\n",
    "        king_positions = {'K': board.king(chess.WHITE), 'k': board.king(chess.BLACK)}\n",
    "        rook_positions = {'R': list(board.pieces(chess.ROOK, chess.WHITE)),\n",
    "                          'r': list(board.pieces(chess.ROOK, chess.BLACK))}\n",
    "        for rook_pos in rook_positions['r']:\n",
    "            if king_positions['K'] and (\n",
    "                    rook_pos // 8 == king_positions['K'] // 8 or rook_pos % 8 == king_positions['K'] % 8):\n",
    "                value -= 50\n",
    "\n",
    "        for rook_pos in rook_positions['R']:\n",
    "            if king_positions['k'] and (\n",
    "                    rook_pos // 8 == king_positions['k'] // 8 or rook_pos % 8 == king_positions['k'] % 8):\n",
    "                value += 50\n",
    "\n",
    "        return value * 0.8\n",
    "\n",
    "    def all_piece_values_and_piece_square_tables(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Calculate the combined value of all pieces on the chessboard.\n",
    "\n",
    "        This function computes the total value of all pieces on the chessboard, considering their intrinsic values and\n",
    "        positional advantages or disadvantages based on piece-square tables. It accounts for both the middle game and endgame\n",
    "        scenarios.\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object).\n",
    "        :return: The combined evaluation score for all pieces on the board. A positive score indicates an advantage for white,\n",
    "                 and a negative score indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        endgame = state.game_representation.is_in_endgame_phase()\n",
    "        # Iterate through all squares on the chessboard and evaluate the value of pieces on each square.\n",
    "        for square, piece in state.game_representation.game_board.piece_map().items():\n",
    "            piece_str = str(piece)\n",
    "            piece_type = piece_str.lower()\n",
    "            piece_value = 0\n",
    "            if piece.piece_type == chess.KING:\n",
    "                if not endgame:\n",
    "                    piece_value = (\n",
    "                            piece_values[piece_type]\n",
    "                            + piece_square_tables[piece_str][\"early\"][square]\n",
    "                    )\n",
    "                else:\n",
    "                    piece_value = (\n",
    "                            piece_values[piece_type]\n",
    "                            + piece_square_tables[piece_str][\"end\"][square]\n",
    "                    )\n",
    "            else:\n",
    "                piece_value = (\n",
    "                        piece_values[piece_type] + piece_square_tables[piece_str][square]\n",
    "                )\n",
    "            # Add or subtract the piece value based on its color (white or black).\n",
    "            total += piece_value if piece.color == chess.WHITE else -piece_value\n",
    "        return total\n",
    "\n",
    "    def center_control(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluate control of the central squares on the chessboard.\n",
    "\n",
    "        This function calculates an evaluation score based on the control of central squares on the chessboard. It awards\n",
    "        points for pieces occupying or influencing central squares, with a bonus for pieces controlled by the player (white)\n",
    "        and a penalty for pieces controlled by the opponent (black).\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object).\n",
    "        :return: The evaluation score for central control. A positive score indicates an advantage for white, and a negative\n",
    "                 score indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        board = state.game_representation.game_board  # Access the chess board from the game state.\n",
    "        center_squares = [chess.D3, chess.E3, chess.D4, chess.E4]\n",
    "        value = 0\n",
    "        for square in center_squares:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                value += 10 if piece.symbol().isupper() else -10\n",
    "        return value * 0.4\n",
    "\n",
    "    def mobility(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluate the mobility of pieces on the chessboard.\n",
    "\n",
    "        This function calculates an evaluation score based on the mobility of pieces on the chessboard. It assesses\n",
    "        the number of legal moves available to each piece, considering their types (pawn, knight, bishop, rook,\n",
    "        queen, king) and assigns scores accordingly. Mobility is a key factor in evaluating a position's strength.\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object). :return: The evaluation score for\n",
    "                piece mobility. A positive score indicates an advantage for white, and a negative score indicates an\n",
    "                advantage for black.\n",
    "        \"\"\"\n",
    "        # Define piece mobility values, specifying the importance of mobility for each piece type.\n",
    "        piece_mobility_values = {\n",
    "            chess.PAWN: 1,\n",
    "            chess.KNIGHT: 3,\n",
    "            chess.BISHOP: 3,\n",
    "            chess.ROOK: 2,\n",
    "            chess.QUEEN: 1,\n",
    "            chess.KING: 1\n",
    "        }\n",
    "\n",
    "        board = state.game_representation.game_board\n",
    "        mobility_value = 0\n",
    "\n",
    "        # Iterate through all squares on the chessboard.\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                # Calculate the legal moves for the current piece.\n",
    "                legal_moves = board.attacks(square)\n",
    "                num_moves = len(legal_moves)\n",
    "                # Calculate a score based on the number of legal moves and the piece's type.\n",
    "                score = num_moves * piece_mobility_values.get(piece.piece_type, 0)\n",
    "                # Add or subtract the score based on the piece's color (white or black).\n",
    "                mobility_value += score if piece.color == board.turn else -score\n",
    "\n",
    "        return mobility_value * 0.6\n",
    "\n",
    "    def attack_value(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluate the value of piece attacks on the chessboard.\n",
    "\n",
    "        This function calculates an evaluation score based on the value of piece attacks on the chessboard. It assesses the\n",
    "        value of pieces that are attacking or defending squares and considers whether a check is present in the position.\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object).\n",
    "        :return: The evaluation score for attack value. A positive score indicates an advantage for white, and a negative\n",
    "                 score indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        board = state.game_representation.game_board\n",
    "        value = 0\n",
    "        # Iterate through all squares on the chessboard.\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                # Determine the value of the piece on the current square.\n",
    "                attacked_value = piece_values[piece.symbol().lower()]\n",
    "                # Find attackers of the square from the opponent's side.\n",
    "                attackers_of_square = board.attackers(not board.turn, square)\n",
    "                if piece.color == board.turn:\n",
    "                    # Subtract the value of attackers if the piece belongs to the player (white).\n",
    "                    value -= len(attackers_of_square) * attacked_value\n",
    "                else:\n",
    "                    # Add the value of attackers if the piece belongs to the opponent (black).\n",
    "                    value += len(attackers_of_square) * attacked_value\n",
    "        # Add a bonus if the position is in check.\n",
    "        if board.is_check():\n",
    "            value += 20\n",
    "        return value * 0.8\n",
    "\n",
    "    def rooks_on_open_files(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluate the presence of rooks on open files in the chessboard.\n",
    "\n",
    "        This function calculates an evaluation score based on the presence of rooks on open files in the chessboard. It assesses\n",
    "        each column (file) to check if it is open (no pawns blocking) and whether there is at least one rook present. A bonus\n",
    "        or penalty is assigned depending on the color of the rook (white or black) and whether the file is open or not.\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object).\n",
    "        :return: The evaluation score for rooks on open files. A positive score indicates an advantage for white, and a negative\n",
    "                 score indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        board = state.game_representation.game_board\n",
    "        value = 0\n",
    "        # Iterate through each column (file) on the chessboard.\n",
    "        for x in range(8):\n",
    "            has_rook = False\n",
    "            open_file = True\n",
    "            rook_color = None\n",
    "            # Iterate through each row (rank) in the current column.\n",
    "            for y in range(8):\n",
    "                piece = board.piece_at(8 * y + x)\n",
    "                if piece and piece.symbol() in ['P', 'p']:\n",
    "                    # If a pawn is found, the file is not open.\n",
    "                    open_file = False\n",
    "                if piece and piece.symbol() in ['R', 'r']:\n",
    "                    # If a rook is found, mark that a rook is present on this file.\n",
    "                    has_rook = True\n",
    "                    rook_color = piece.color\n",
    "            # Check if the file is open and there is at least one rook present.\n",
    "            if open_file and has_rook:\n",
    "                # Assign a bonus or penalty based on the color of the rook.\n",
    "                value += 25 if rook_color == chess.WHITE else -25\n",
    "        return value * 0.4\n",
    "\n",
    "    def check_forks(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluate the presence of fork opportunities in the chess position.\n",
    "\n",
    "        This function calculates an evaluation score based on the presence of fork opportunities in the chess\n",
    "        position. It considers legal moves for the current player and checks whether each move results in multiple\n",
    "        attackers on a single square, potentially creating a fork. A bonus is assigned for each detected fork\n",
    "        opportunity.\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object).\n",
    "        :return: The evaluation score for fork opportunities. A positive score indicates an advantage for white,\n",
    "                and a negative score indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        board = state.game_representation.game_board\n",
    "        forks_value = 0\n",
    "        # Iterate through all legal moves for the current player.\n",
    "        for move in board.legal_moves:\n",
    "            # Make the move on the board temporarily.\n",
    "            board.push(move)\n",
    "            # Find attackers after the move to the destination square.\n",
    "            attacks_after_move = board.attackers(board.turn, move.to_square)\n",
    "            # Check if multiple attackers are present on the same square, indicating a fork opportunity.\n",
    "            if len(attacks_after_move) > 1:\n",
    "                forks_value += 10\n",
    "            # Undo the move to explore other moves.\n",
    "            board.pop()\n",
    "        return forks_value * 0.6\n",
    "\n",
    "    def check_pins(self, state: StateChessGame):\n",
    "        \"\"\"\n",
    "        Evaluate the presence of pinned pieces in the chess position.\n",
    "\n",
    "        This function calculates an evaluation score based on the presence of pinned pieces in the chess position. It\n",
    "        checks each square on the chessboard to identify pieces that belong to the current player (not opponent) and\n",
    "        determines if any of those pieces are pinned by an opponent's piece. A penalty is assigned for each detected\n",
    "        pinned piece.\n",
    "\n",
    "        :param state: The current state of the chess game (StateChessGame object).\n",
    "        :return: The evaluation score for pinned pieces. A positive score indicates an advantage for white,\n",
    "                and a negative score indicates an advantage for black.\n",
    "        \"\"\"\n",
    "        board = state.game_representation.game_board\n",
    "        pins_value = 0\n",
    "        opponent_color = not board.turn\n",
    "        # Iterate through all squares on the chessboard.\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            # Check if there is a piece on the square, and if it belongs to the current player.\n",
    "            if piece and piece.color == board.turn:\n",
    "                # Find attackers of the square by the opponent.\n",
    "                attackers = board.attackers(opponent_color, square)\n",
    "                for attacker_square in attackers:\n",
    "                    # Check if the piece on the square is pinned.\n",
    "                    attacker_piece = board.piece_at(attacker_square)\n",
    "                    if board.is_pinned(board.turn, attacker_square):\n",
    "                        # If pinned, assign a penalty to the evaluation score.\n",
    "                        pins_value -= 10\n",
    "\n",
    "        return pins_value * 0.4\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.382306600Z",
     "start_time": "2023-10-29T17:06:19.351950400Z"
    }
   },
   "id": "9f6ca383cca2db01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search Algorithm\n",
    "## MinMax"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf3857457ff49a51"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class MinMax:\n",
    "    \"\"\"\n",
    "    Implementation of the Minimax algorithm for game state evaluation and decision-making.\n",
    "\n",
    "    Attributes:\n",
    "        game: An instance of a game object which provides interface methods for the game state and its neighbors.\n",
    "        heuristic: An instance of a heuristic object used to evaluate game states.\n",
    "        max_depth: The maximum depth for the minimax search. Default is 1.\n",
    "        eval_count: Count of the evaluations performed during the search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, heuristic, max_depth=1):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the MinMax class.\n",
    "        :param game: The game for which the search is performed.\n",
    "        :param heuristic: The heuristic used to evaluate the game states.\n",
    "        :param max_depth: The maximum depth of the search. Default is 1.\n",
    "        \"\"\"\n",
    "        self.game = game\n",
    "        self.heuristic = heuristic\n",
    "        self.max_depth = max_depth\n",
    "        self.eval_count = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def pick(states, parent_turn):\n",
    "        \"\"\"\n",
    "        Picks the best state based on the heuristic values.\n",
    "\n",
    "        This static method selects the best game state from a list of states based on their heuristic values.\n",
    "        The selection is determined by whether it's the maximizing player's turn or the minimizing player's turn.\n",
    "\n",
    "        :param states: List of game states to pick from.\n",
    "        :param parent_turn: Indicates whose turn it is: True for the player trying to maximize and False for\n",
    "                            the player trying to minimize.\n",
    "        :return: The best state based on the heuristic value.\n",
    "        \"\"\"\n",
    "        if parent_turn:\n",
    "            return max(states, key=lambda state: state.h)  # Select the state with the highest heuristic value.\n",
    "        else:\n",
    "            return min(states, key=lambda state: state.h)  # Select the state with the lowest heuristic value.\n",
    "\n",
    "    def evaluate(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Evaluates a list of game states using the Minimax algorithm.\n",
    "\n",
    "        This method evaluates a list of game states using the Minimax algorithm, which is a decision-making algorithm in\n",
    "        game theory for minimizing the possible loss for a worst-case scenario. It assigns heuristic values to\n",
    "        each state based on the algorithm's calculations.\n",
    "\n",
    "        :param states: List of game states to evaluate.\n",
    "        :param parent_turn: Indicates whose turn it is: True for the player trying to maximize and False\n",
    "                            for the player trying to minimize.\n",
    "        \"\"\"\n",
    "        for state in states:\n",
    "            if state.can_claim_draw():\n",
    "                state.h = 0.0  # Set the heuristic value to 0 if the game can be claimed as a draw.\n",
    "            else:\n",
    "                # Calculate heuristic value using Minimax.\n",
    "                state.h = self.__minmax(state, self.max_depth - 1, not parent_turn)\n",
    "\n",
    "    def __minmax(self, state, depth, turn):\n",
    "        \"\"\"\n",
    "        Recursive helper method to perform the Minimax search.\n",
    "\n",
    "        This private method performs a recursive Minimax search on a game tree to determine the heuristic\n",
    "        value of a given game state.\n",
    "\n",
    "        :param state: The current game state.\n",
    "        :param depth: The current depth in the search.\n",
    "        :param turn: Indicates whose turn it is: True for the player trying to maximize and False for the player\n",
    "                    trying to minimize.\n",
    "        :return: Heuristic value of the provided game state.\n",
    "        \"\"\"\n",
    "        self.eval_count += 1  # Increment evaluation count.\n",
    "        neighbors = self.game.neighbors(state)  # Get neighboring states from the current state.\n",
    "\n",
    "        # Base cases: If the search depth is 0 or if the game is in an endgame state, return the heuristic value.\n",
    "        if depth == 0 or state.is_endgame():\n",
    "            return self.heuristic.h(state)\n",
    "\n",
    "        if turn:\n",
    "            value = -np.inf  # Initialize value for maximizing player to negative infinity.\n",
    "            for child in neighbors:\n",
    "                value = max(value, self.__minmax(child, depth - 1, False))  # Recursively maximize.\n",
    "            return value\n",
    "        else:\n",
    "            value = np.inf  # Initialize value for minimizing player to positive infinity.\n",
    "            for child in neighbors:\n",
    "                value = min(value, self.__minmax(child, depth - 1, True))  # Recursively minimize.\n",
    "            return value\n",
    "\n",
    "    def search(self, state):\n",
    "        \"\"\"\n",
    "        Initiates the Minimax search for a given game state.\n",
    "\n",
    "        This method initializes the Minimax search process for a given game state.\n",
    "        It calculates the heuristic values for the neighboring states and selects the best next state based\n",
    "        on the Minimax algorithm.\n",
    "\n",
    "        :param state: The game state to start the search from.\n",
    "        :return:  Best next game state based on the Minimax algorithm.\n",
    "        \"\"\"\n",
    "        neighbors = self.game.neighbors(state)  # Get neighboring states from the current state.\n",
    "        self.evaluate(neighbors, state.turn())  # Calculate heuristic values for the neighbors.\n",
    "        return self.pick(neighbors, state.turn())  # Select the best next state using the Minimax algorithm.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.411333200Z",
     "start_time": "2023-10-29T17:06:19.383314100Z"
    }
   },
   "id": "7d0c44fa011a4d92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MinMaxAlphaBetaPruning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0116240b6156f5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class MinMaxAlphaBetaPruning:\n",
    "    \"\"\"\n",
    "    Implementation of Minimax algorithm with Alpha-Beta pruning.\n",
    "\n",
    "    Attributes:\n",
    "        game: An instance of a game object that provides interface methods for the game state and its neighbors.\n",
    "        heuristic: An instance of a heuristic object used to evaluate game states.\n",
    "        max_depth: Maximum depth for the minimax search. Default is 1.\n",
    "        prune_count: Count of the times pruning occurred during the search.\n",
    "        eval_count: Count of the evaluations performed during the search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, heuristic, max_depth=1):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the MinMaxAlphaBetaPruning class.\n",
    "        :param game: The game for which the search is performed.\n",
    "        :param heuristic: The heuristic to evaluate the game states.\n",
    "        :param max_depth: Maximum depth of the search. Default is 1.\n",
    "        \"\"\"\n",
    "        self.game = game\n",
    "        self.heuristic = heuristic\n",
    "        self.max_depth = max_depth\n",
    "        self.prune_count = 0\n",
    "        self.eval_count = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def pick(states, parent_turn):\n",
    "        \"\"\"\n",
    "        Picks the best state based on the heuristic values.\n",
    "\n",
    "        This function evaluates a list of game states and selects the state that optimizes\n",
    "        the current player's position.\n",
    "        If it is the maximizing player's turn (parent_turn is True), the state with the highest heuristic\n",
    "        value is chosen.\n",
    "        Otherwise, if it is the minimizing player's turn (parent_turn is False), the state with the lowest heuristic\n",
    "        value is chosen.\n",
    "\n",
    "        :param states: List of game states to pick from.\n",
    "        :param parent_turn: Indicates whose turn it is: True for maximizing player and False for minimizing player.\n",
    "        :return: The best state based on the heuristic value.\n",
    "        \"\"\"\n",
    "        if parent_turn:\n",
    "            # If it's the maximizing player's turn, select the state with the highest heuristic value.\n",
    "            return max(states, key=lambda state: state.h)\n",
    "        else:\n",
    "            # If it's the minimizing player's turn, select the state with the lowest heuristic value.\n",
    "            return min(states, key=lambda state: state.h)\n",
    "\n",
    "    def evaluate(self, states, parent_turn):\n",
    "        \"\"\"\n",
    "        Evaluates a list of game states using the Minimax algorithm with Alpha-Beta pruning.\n",
    "\n",
    "        This function evaluates a list of game states using the Minimax algorithm with Alpha-Beta pruning.\n",
    "        It assigns a heuristic value to each state based on its evaluation at a specified depth in the game tree.\n",
    "        The depth of the evaluation is determined by the 'max_depth' attribute of the object.\n",
    "\n",
    "        :param states: List of game states to evaluate.\n",
    "        :param parent_turn: Indicates whose turn it is: True for maximizing player and False for minimizing player.\n",
    "        \"\"\"\n",
    "        for state in states:\n",
    "            if state.can_claim_draw():\n",
    "                # If the state can claim a draw, assign a heuristic value of 0.\n",
    "                state.h = 0.0\n",
    "            else:\n",
    "                # Otherwise, use the Minimax algorithm with Alpha-Beta pruning to assign a heuristic value.\n",
    "                state.h = self.__minmax_alpha_beta(state, self.max_depth - 1, -np.inf, np.inf, not parent_turn)\n",
    "\n",
    "    def __minmax_alpha_beta(self, state, depth, alpha, beta, turn):\n",
    "        \"\"\"\n",
    "        Recursive helper method to perform Minimax search with Alpha-Beta pruning.\n",
    "\n",
    "        This private method performs a recursive Minimax search with Alpha-Beta pruning to find the optimal move\n",
    "        in the game tree.\n",
    "        It evaluates the provided game state and returns a heuristic value based on the current player's turn.\n",
    "\n",
    "        :param state: Current game state.\n",
    "        :param depth: Current depth in the search.\n",
    "        :param alpha: Best already explored option for the maximizer.\n",
    "        :param beta: Best already explored option for the minimizer.\n",
    "        :param turn: Indicates whose turn it is: True for maximizing player and False for minimizing player.\n",
    "        :return: Heuristic value of the provided game state.\n",
    "        \"\"\"\n",
    "        self.eval_count += 1  # Count the number of state evaluations.\n",
    "        neighbors = self.game.neighbors(state)  # Generate possible successor states.\n",
    "\n",
    "        if depth == 0 or state.is_endgame():\n",
    "            # Base case: If the maximum depth is reached or the state represents an endgame, return the heuristic value.\n",
    "            return self.heuristic.h(state)\n",
    "\n",
    "        if turn:  # Maximizing player\n",
    "            value = -np.inf\n",
    "            for neighbor in neighbors:\n",
    "                value = max(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, False))\n",
    "                alpha = max(alpha, value)  # Update alpha with the maximum value found so far.\n",
    "                if alpha >= beta:  # Alpha-Beta pruning: Stop evaluating if alpha is greater than or equal to beta.\n",
    "                    self.prune_count += 1  # Count pruned branches.\n",
    "                    break\n",
    "            return value\n",
    "        else:  # Minimizing player\n",
    "            value = np.inf\n",
    "            for neighbor in neighbors:\n",
    "                value = min(value, self.__minmax_alpha_beta(neighbor, depth - 1, alpha, beta, True))\n",
    "                beta = min(beta, value)  # Update beta with the minimum value found so far.\n",
    "                if beta <= alpha:  # Alpha-Beta pruning: Stop evaluating if beta is less than or equal to alpha.\n",
    "                    self.prune_count += 1  # Count pruned branches.\n",
    "                    break\n",
    "            return value\n",
    "\n",
    "    def search(self, state):\n",
    "        \"\"\"\n",
    "        Initiates the Minimax search with Alpha-Beta pruning for a given game state.\n",
    "\n",
    "        This method initializes the Minimax search with Alpha-Beta pruning to find the best next game state based on the\n",
    "        current game state.\n",
    "        It evaluates the neighboring states, chooses the best move, and returns the resulting game state.\n",
    "\n",
    "        :param state: The game state to search from.\n",
    "        :return: Best next game state based on the Minimax algorithm with Alpha-Beta pruning.\n",
    "        \"\"\"\n",
    "        neighbors = self.game.neighbors(state)  # Generate possible successor states.\n",
    "        self.evaluate(neighbors, state.turn())  # Evaluate the neighboring states using Minimax.\n",
    "        return self.pick(neighbors, state.turn())  # Choose and return the best next game state.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:06:19.415337200Z",
     "start_time": "2023-10-29T17:06:19.391615400Z"
    }
   },
   "id": "15ea252b8546ba0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Method Main"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a6bdd6a71c26e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The game of chess begins!\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . N . .\n",
      "P P P P P P P P\n",
      "R N B Q K B . R\n",
      "Agent 1 (WHITE) played the move: g1f3\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . .\n",
      ". . . . . N . .\n",
      "P P P P P P P P\n",
      "R N B Q K B . R\n",
      "Agent 2 (BLACK) played the move: d7d5\n",
      "r n b q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . P\n",
      ". . . . . N . .\n",
      "P P P P P P P .\n",
      "R N B Q K B . R\n",
      "Agent 1 (WHITE) played the move: h2h4\n",
      "r n . q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . P\n",
      ". . . . . N . b\n",
      "P P P P P P P .\n",
      "R N B Q K B . R\n",
      "Agent 2 (BLACK) played the move: c8h3\n",
      "r n . q k b n r\n",
      "p p p . p p p p\n",
      ". . . . . . . .\n",
      ". . . p . . . .\n",
      ". . . . . . . P\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 1 (WHITE) played the move: h1h3\n",
      "r n . q k b n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . p .\n",
      ". . . . . . . P\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 2 (BLACK) played the move: g7g5\n",
      "r n . q k b n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . P .\n",
      ". . . . . . . .\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 1 (WHITE) played the move: h4g5\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . b\n",
      ". . . p . . P .\n",
      ". . . . . . . .\n",
      ". . . . . N . R\n",
      "P P P P P P P .\n",
      "R N B Q K B . .\n",
      "Agent 2 (BLACK) played the move: f8h6\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . b\n",
      ". . . p . . P .\n",
      ". . . . . . . .\n",
      ". . N . . N . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: b1c3\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . b .\n",
      ". . . . . . . .\n",
      ". . N . . N . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: h6g5\n",
      "r n . q k . n r\n",
      "p p p . p p . p\n",
      ". . . . . . . .\n",
      ". . . p . . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: f3g5\n",
      "r n . q k . . r\n",
      "p p p . p p . p\n",
      ". . . . . . . n\n",
      ". . . p . . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . R\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: g8h6\n",
      "r n . q k . . r\n",
      "p p p . p p . p\n",
      ". . . . . . . n\n",
      ". . . p . . N .\n",
      ". . . . . . . .\n",
      ". . N . R . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: h3e3\n",
      "r n . q k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p p . N .\n",
      ". . . . . . . .\n",
      ". . N . R . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: e7e5\n",
      "r n . q k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p R . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: e3e5\n",
      "\n",
      "r n . . k . . r\n",
      "p p p . q p . p\n",
      ". . . . . . . n\n",
      ". . . p R . N .\n",
      ". . . . . . . .\n",
      ". . N . . . . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: d8e7\n",
      "r n . . k . . r\n",
      "p p p . q p . p\n",
      ". . . . . . . n\n",
      ". . . p R . . .\n",
      ". . . . . . . .\n",
      ". . N . . N . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: g5f3\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p q . . .\n",
      ". . . . . . . .\n",
      ". . N . . N . .\n",
      "P P P P P P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: e7e5\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p q . . .\n",
      ". . . . P . . .\n",
      ". . N . . N . .\n",
      "P P P P . P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: e2e4\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p . . . .\n",
      ". . . . P . . .\n",
      ". . q . . N . .\n",
      "P P P P . P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: e5c3\n",
      "r n . . k . . r\n",
      "p p p . . p . p\n",
      ". . . . . . . n\n",
      ". . . p . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B Q K B . .\n",
      "Agent 1 (WHITE) played the move: d2c3\n",
      "r . . . k . . r\n",
      "p p p . . p . p\n",
      "n . . . . . . n\n",
      ". . . p . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B Q K B . .\n",
      "Agent 2 (BLACK) played the move: b8a6\n",
      "r . . . k . . r\n",
      "p p p . . p . p\n",
      "n . . . . . . n\n",
      ". . . Q . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 1 (WHITE) played the move: d1d5\n",
      ". . . r k . . r\n",
      "p p p . . p . p\n",
      "n . . . . . . n\n",
      ". . . Q . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 2 (BLACK) played the move: a8d8\n",
      ". . . r k . . r\n",
      "p p p . . p . p\n",
      "n . . . Q . . n\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 1 (WHITE) played the move: d5e6\n",
      "\n",
      ". . . r k . . r\n",
      "p p p . . . . p\n",
      "n . . . p . . n\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K B . .\n",
      "Agent 2 (BLACK) played the move: f7e6\n",
      ". . . r k . . r\n",
      "p p p . . . . p\n",
      "n . . . p . . n\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K . . .\n",
      "Agent 1 (WHITE) played the move: f1b5\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . p . . n\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . B . K . . .\n",
      "Agent 2 (BLACK) played the move: d8d7\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . p . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: c1h6\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . p . . .\n",
      ". . . . P . . .\n",
      ". . P . . N . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e6e5\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: f3e5\n",
      ". . . . k r . .\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h8f8\n",
      ". . . . k r . .\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e5f7\n",
      ". . . . k . . r\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: f8h8\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: f7e5\n",
      ". . . . k r . .\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . N . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h8f8\n",
      ". . . . k r . .\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e5f7\n",
      ". . . . k . . r\n",
      "p p p r . N . p\n",
      "n . . . . . . B\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: f8h8\n",
      ". . . . k . . r\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: f7g5\n",
      ". . . . k r . .\n",
      "p p p r . . . p\n",
      "n . . . . . . B\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h8f8\n",
      ". . . . k B . .\n",
      "p p p r . . . p\n",
      "n . . . . . . .\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: h6f8\n",
      ". . . . . k . .\n",
      "p p p r . . . p\n",
      "n . . . . . . .\n",
      ". B . . . . N .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e8f8\n",
      ". . . . . k . .\n",
      "p p p r . . . p\n",
      "n . . . N . . .\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: g5e6\n",
      "\n",
      ". . . . . . . .\n",
      "p p p r k . . p\n",
      "n . . . N . . .\n",
      ". B . . . . . .\n",
      ". . . . P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: f8e7\n",
      ". . . . . . . .\n",
      "p p p r k . . p\n",
      "n . . . . . . .\n",
      ". B . . . . . .\n",
      ". . . N P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e6d4\n",
      ". . . . . . . .\n",
      "p p p . k . . p\n",
      "n . . . . . . .\n",
      ". B . . . . . .\n",
      ". . . r P . . .\n",
      ". . P . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: d7d4\n",
      ". . . . . . . .\n",
      "p p p . k . . p\n",
      "n . . . . . . .\n",
      ". B . . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: c3d4\n",
      ". . . . . . . .\n",
      "p p . . k . . p\n",
      "n . . . . . . .\n",
      ". B p . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: c7c5\n",
      ". . . . . . . .\n",
      "p p . . k . . p\n",
      "n . . . . . . .\n",
      ". . p . . . . .\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . B P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: b5e2\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . p . . . . p\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . B P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: h7h5\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . p . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: e2h5\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . p P . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: c5d4\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      "n . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . p P . . .\n",
      "P . . . . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: a2a3\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". n . p P . . .\n",
      "P . . . . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: a6b4\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". P . p P . . .\n",
      ". . . . . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: a3b4\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". P . . P . . .\n",
      ". . . p . . . .\n",
      ". P P . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: d4d3\n",
      ". . . . . . . .\n",
      "p p . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". P . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: c2d3\n",
      ". . . . . . . .\n",
      ". p . . k . . .\n",
      ". . . . . . . .\n",
      "p . . . . . . B\n",
      ". P . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: a7a5\n",
      ". . . . . . . .\n",
      ". p . . k . . .\n",
      ". . . . . . . .\n",
      "P . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: b4a5\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". p . . . . . .\n",
      "P . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: b7b6\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". P . . . . . .\n",
      ". . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: a5b6\n",
      "\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . B\n",
      ". . . . P . . .\n",
      ". . . P . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e7e6\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 1 (WHITE) played the move: d3d4\n",
      "\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      "R . . . K . . .\n",
      "Agent 2 (BLACK) played the move: e6d6\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: a1c1\n",
      "\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: d6e6\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: b6b7\n",
      "\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: e6d6\n",
      ". Q . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: b7b8q\n",
      "\n",
      ". Q . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: d6e7\n",
      ". . . . Q . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: b8e8\n",
      "\n",
      ". . . . Q . . .\n",
      ". . . . . . . .\n",
      ". . . . . k . .\n",
      ". . . . . . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 2 (BLACK) played the move: e7f6\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . k . .\n",
      ". . . . Q . . B\n",
      ". . . P P . . .\n",
      ". . . . . . . .\n",
      ". P . . . P P .\n",
      ". . R . K . . .\n",
      "Agent 1 (WHITE) played the move: e8e5\n",
      "\n",
      "Result in: 66477.95ms\n",
      "OUTCOME: CHECKMATE\n",
      "Player Win: WHITE\n",
      "Number of Moves       (agent 1 WHITHE): 38\n",
      "States evaluated      (agent 1 WHITHE): 20035\n",
      "Pruning carried out   (agent 1 WHITHE): 0\n",
      "\n",
      "Number of Moves       (agent 2 BLACK): 37\n",
      "States evaluated      (agent 2 BLACK): 15004\n",
      "Pruning carried out   (agent 2 BLACK): 2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def main_chess_game():\n",
    "    game = ChessGame()\n",
    "    heuristic_a1 = HardBoardEvaluationChessGame()\n",
    "    search_algorithm_a1 = MinMaxAlphaBetaPruning(game=game, heuristic=heuristic_a1, max_depth=2)\n",
    "    search_algorithm_a2 = MinMaxAlphaBetaPruning(game=game, heuristic=heuristic_a1, max_depth=2)\n",
    "    state = StateChessGame()\n",
    "    agent1 = Agent(search_algorithm_a1, state)\n",
    "    agent2 = Agent(search_algorithm_a2, state)\n",
    "    turn_agent = 0\n",
    "    move_agent_1 = 1\n",
    "    move_agent_2 = 1\n",
    "    start_time = time.time()\n",
    "    print(\"The game of chess begins!\")\n",
    "    print(state.game_representation)\n",
    "    while not state.is_endgame():\n",
    "        if turn_agent % 2:\n",
    "            state = agent2.do_action(state)\n",
    "            move_agent_2 += 1\n",
    "            print(state.game_representation)\n",
    "            print(\"Agent 2 (BLACK) played the move:\", state.move)\n",
    "            print()\n",
    "        else:\n",
    "            state = agent1.do_action(state)\n",
    "            move_agent_1 += 1\n",
    "            print(state.game_representation)\n",
    "            print(\"Agent 1 (WHITE) played the move:\", state.move)\n",
    "            print()\n",
    "        turn_agent = turn_agent + 1\n",
    "\n",
    "        if state is None:\n",
    "            print(\"The agent was unable to resolve the issue\")\n",
    "            return\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Result in: {(end_time - start_time) * 1000:.2f}ms\")\n",
    "    print(\n",
    "        f\"OUTCOME: {state.game_representation.game_board.outcome().termination.name}\")\n",
    "    if state.game_representation.get_name_winner_player() is not None:\n",
    "        print(f\"Player Win: {state.game_representation.get_name_winner_player().upper()}\")\n",
    "    print(f\"Number of Moves       (agent 1 WHITHE): {move_agent_1}\")\n",
    "    print(f\"States evaluated      (agent 1 WHITHE): {agent1.search_algorithm.eval_count}\")\n",
    "    print(f\"Pruning carried out   (agent 1 WHITHE): {agent1.search_algorithm.prune_count}\")\n",
    "    print()\n",
    "    print(f\"Number of Moves       (agent 2 BLACK): {move_agent_2}\")\n",
    "    print(f\"States evaluated      (agent 2 BLACK): {agent2.search_algorithm.eval_count}\")\n",
    "    print(f\"Pruning carried out   (agent 2 BLACK): {agent2.search_algorithm.prune_count}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_chess_game()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T17:07:25.893770600Z",
     "start_time": "2023-10-29T17:06:19.405814300Z"
    }
   },
   "id": "c749630f46dcfd5f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
